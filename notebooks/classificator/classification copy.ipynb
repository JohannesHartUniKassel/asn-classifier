{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a33344",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "## Peeringdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c32292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "org_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "aka",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name_long",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "website",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "social_media",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "asn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "looking_glass",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "route_server",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "irr_as_set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_types",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_prefixes4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "info_prefixes6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "info_traffic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_ratio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_scope",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_unicast",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "info_multicast",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "info_ipv6",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "info_never_via_route_servers",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ix_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fac_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "notes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "netixlan_updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "netfac_updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "poc_updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "policy_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "policy_general",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "policy_locations",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "policy_ratio",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "policy_contracts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "allow_ixp_update",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "status_dashboard",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rir_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rir_status_updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "logo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "748ece37-6e16-449a-be93-598768dd2db2",
       "rows": [
        [
         "0",
         "1",
         "8897",
         "GTT Communications (AS4436)",
         "Formerly known as nLayer Communications",
         "",
         "http://www.gtt.net",
         "[{'service': 'website', 'identifier': 'http://www.gtt.net'}]",
         "4436",
         "",
         "",
         "",
         "NSP",
         "['NSP']",
         "200000.0",
         "10000.0",
         "",
         "",
         "Global",
         "True",
         "False",
         "True",
         "False",
         "0",
         "0",
         "nLayer / AS4436 has been acquired by GTT Communications / AS3257 and is no longer directly peering.  Please refer all peering related inquiries to peering [at] gtt [dot] net.",
         "2021-09-22T00:06:59Z",
         "2016-09-19T05:47:27Z",
         "2016-03-14T21:53:18Z",
         "http://www.gtt.net/peering/",
         "Restrictive",
         "Required - International",
         "True",
         "Required",
         "False",
         null,
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2022-07-27T05:33:22Z",
         "ok"
        ],
        [
         "1",
         "2",
         "14",
         "Akamai Technologies",
         "",
         "",
         "https://www.akamai.com/",
         "[{'service': 'website', 'identifier': 'https://www.akamai.com/'}]",
         "20940",
         "",
         "",
         "AS-AKAMAI",
         "Content",
         "['Content']",
         "12000.0",
         "5000.0",
         "100+Tbps",
         "Heavy Outbound",
         "Global",
         "True",
         "False",
         "True",
         "False",
         "231",
         "217",
         "",
         "2025-10-20T12:15:26Z",
         "2025-09-18T10:39:32Z",
         "2021-05-11T21:26:32Z",
         "",
         "Open",
         "Not Required",
         "False",
         "Not Required",
         "False",
         "https://www.akamaistatus.com/",
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2025-10-20T12:16:12Z",
         "ok"
        ],
        [
         "2",
         "3",
         "17",
         "DALnet IRC Network",
         "",
         "",
         "http://www.dal.net",
         "[{'service': 'website', 'identifier': 'http://www.dal.net'}]",
         "31800",
         "",
         "",
         "AS31800",
         "Non-Profit",
         "['Non-Profit']",
         "2.0",
         "0.0",
         "100-1000Mbps",
         "Heavy Inbound",
         "Global",
         "True",
         "False",
         "False",
         "False",
         "15",
         "0",
         "",
         "2025-01-09T13:41:48Z",
         null,
         "2016-03-14T21:22:01Z",
         "http://peering.dal.net",
         "Open",
         "Preferred",
         "False",
         "Not Required",
         "False",
         "",
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2025-01-09T13:42:07Z",
         "ok"
        ],
        [
         "3",
         "5",
         "9350",
         "Swisscom",
         "IP-Plus",
         "",
         "http://www.swisscom.com",
         "[{'service': 'website', 'identifier': 'http://www.swisscom.com'}]",
         "3303",
         "",
         "telnet://route-server.ip-plus.net",
         "RIPE::AS3303:AS-SWCMGLOBAL",
         "Cable/DSL/ISP",
         "['Cable/DSL/ISP']",
         "10000.0",
         "1800.0",
         "1-5Tbps",
         "Mostly Inbound",
         "Europe",
         "True",
         "False",
         "True",
         "False",
         "63",
         "32",
         "",
         "2025-10-16T06:47:17Z",
         "2025-04-10T13:25:48Z",
         "2020-01-22T04:24:08Z",
         "https://www.swisscom.ch/content/dam/swisscom/de/ws/documents/d-ott-dokumente/20230101_swisscom-peering-policy.pdf",
         "Selective",
         "Preferred",
         "True",
         "Required",
         "False",
         "",
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2025-08-12T06:33:30Z",
         "ok"
        ],
        [
         "4",
         "6",
         "23",
         "Cox Communications",
         "Cox Communications",
         "",
         "http://www.cox.com/peering",
         "[{'service': 'website', 'identifier': 'http://www.cox.com/peering'}]",
         "22773",
         "",
         "",
         "AS22773:AS-CONE",
         "Cable/DSL/ISP",
         "['Cable/DSL/ISP']",
         "10000.0",
         "3000.0",
         "100-200Gbps",
         "Mostly Inbound",
         "North America",
         "True",
         "False",
         "True",
         "False",
         "0",
         "14",
         "",
         null,
         "2022-03-24T19:56:00Z",
         "2024-03-06T01:56:24Z",
         "http://www.cox.com/peering",
         "Selective",
         "Preferred",
         "False",
         "Required",
         "False",
         "",
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2022-11-28T22:55:17Z",
         "ok"
        ]
       ],
       "shape": {
        "columns": 41,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org_id</th>\n",
       "      <th>name</th>\n",
       "      <th>aka</th>\n",
       "      <th>name_long</th>\n",
       "      <th>website</th>\n",
       "      <th>social_media</th>\n",
       "      <th>asn</th>\n",
       "      <th>looking_glass</th>\n",
       "      <th>route_server</th>\n",
       "      <th>...</th>\n",
       "      <th>policy_ratio</th>\n",
       "      <th>policy_contracts</th>\n",
       "      <th>allow_ixp_update</th>\n",
       "      <th>status_dashboard</th>\n",
       "      <th>rir_status</th>\n",
       "      <th>rir_status_updated</th>\n",
       "      <th>logo</th>\n",
       "      <th>created</th>\n",
       "      <th>updated</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8897</td>\n",
       "      <td>GTT Communications (AS4436)</td>\n",
       "      <td>Formerly known as nLayer Communications</td>\n",
       "      <td></td>\n",
       "      <td>http://www.gtt.net</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>4436</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Required</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2022-07-27T05:33:22Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Akamai Technologies</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.akamai.com/</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'https:/...</td>\n",
       "      <td>20940</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Required</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.akamaistatus.com/</td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-10-20T12:16:12Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>DALnet IRC Network</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>http://www.dal.net</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>31800</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Required</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-01-09T13:42:07Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>9350</td>\n",
       "      <td>Swisscom</td>\n",
       "      <td>IP-Plus</td>\n",
       "      <td></td>\n",
       "      <td>http://www.swisscom.com</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>3303</td>\n",
       "      <td></td>\n",
       "      <td>telnet://route-server.ip-plus.net</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Required</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-08-12T06:33:30Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>Cox Communications</td>\n",
       "      <td>Cox Communications</td>\n",
       "      <td></td>\n",
       "      <td>http://www.cox.com/peering</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>22773</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Required</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2022-11-28T22:55:17Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  org_id                         name  \\\n",
       "0   1    8897  GTT Communications (AS4436)   \n",
       "1   2      14          Akamai Technologies   \n",
       "2   3      17           DALnet IRC Network   \n",
       "3   5    9350                     Swisscom   \n",
       "4   6      23           Cox Communications   \n",
       "\n",
       "                                       aka name_long  \\\n",
       "0  Formerly known as nLayer Communications             \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                  IP-Plus             \n",
       "4                       Cox Communications             \n",
       "\n",
       "                      website  \\\n",
       "0          http://www.gtt.net   \n",
       "1     https://www.akamai.com/   \n",
       "2          http://www.dal.net   \n",
       "3     http://www.swisscom.com   \n",
       "4  http://www.cox.com/peering   \n",
       "\n",
       "                                        social_media    asn looking_glass  \\\n",
       "0  [{'service': 'website', 'identifier': 'http://...   4436                 \n",
       "1  [{'service': 'website', 'identifier': 'https:/...  20940                 \n",
       "2  [{'service': 'website', 'identifier': 'http://...  31800                 \n",
       "3  [{'service': 'website', 'identifier': 'http://...   3303                 \n",
       "4  [{'service': 'website', 'identifier': 'http://...  22773                 \n",
       "\n",
       "                        route_server  ... policy_ratio policy_contracts  \\\n",
       "0                                     ...         True         Required   \n",
       "1                                     ...        False     Not Required   \n",
       "2                                     ...        False     Not Required   \n",
       "3  telnet://route-server.ip-plus.net  ...         True         Required   \n",
       "4                                     ...        False         Required   \n",
       "\n",
       "  allow_ixp_update               status_dashboard  rir_status  \\\n",
       "0            False                           None          ok   \n",
       "1            False  https://www.akamaistatus.com/          ok   \n",
       "2            False                                         ok   \n",
       "3            False                                         ok   \n",
       "4            False                                         ok   \n",
       "\n",
       "     rir_status_updated  logo               created               updated  \\\n",
       "0  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2022-07-27T05:33:22Z   \n",
       "1  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2025-10-20T12:16:12Z   \n",
       "2  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2025-01-09T13:42:07Z   \n",
       "3  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2025-08-12T06:33:30Z   \n",
       "4  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2022-11-28T22:55:17Z   \n",
       "\n",
       "   status  \n",
       "0      ok  \n",
       "1      ok  \n",
       "2      ok  \n",
       "3      ok  \n",
       "4      ok  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "filepath = Path('../../preprocessing/data/peeringdb/peeringdb_2_dump_2025_10_21.json')\n",
    "\n",
    "with filepath.open('r', encoding='utf-8') as f:\n",
    "    dump = json.load(f)\n",
    "\n",
    "# extract the net.data section and load into a DataFrame\n",
    "net_data = dump.get('net', {}).get('data')\n",
    "if net_data is None:\n",
    "    raise KeyError(\"JSON does not contain 'net' -> 'data' structure\")\n",
    "\n",
    "net_df = pd.DataFrame(net_data)\n",
    "net_df['asn'] = net_df['asn'].astype(int)\n",
    "net_df = net_df[net_df['info_type'] != '']\n",
    "\n",
    "# show a quick preview\n",
    "net_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f20d5",
   "metadata": {},
   "source": [
    "# Caida AS Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c190e0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "aut",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "changed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "org_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "org_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1251251e-5fbe-4ff4-b9bc-f9d331fdb09c",
       "rows": [
        [
         "0",
         "1",
         "20240618.0",
         "LPL-141-ARIN",
         "ARIN",
         "Level 3 Parent, LLC",
         "US"
        ],
        [
         "1",
         "2",
         "20231108.0",
         "UNIVER-19-Z-ARIN",
         "ARIN",
         "University of Delaware",
         "US"
        ],
        [
         "2",
         "3",
         "20100927.0",
         "MIT-2-ARIN",
         "ARIN",
         "Massachusetts Institute of Technology",
         "US"
        ],
        [
         "3",
         "4",
         "20230929.0",
         "USC-32-Z-ARIN",
         "ARIN",
         "University of Southern California",
         "US"
        ],
        [
         "4",
         "5",
         "20200723.0",
         "WGL-117-ARIN",
         "ARIN",
         "WFA Group LLC",
         "US"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aut</th>\n",
       "      <th>changed</th>\n",
       "      <th>org_id</th>\n",
       "      <th>source</th>\n",
       "      <th>org_name</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20240618.0</td>\n",
       "      <td>LPL-141-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Level 3 Parent, LLC</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20231108.0</td>\n",
       "      <td>UNIVER-19-Z-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>University of Delaware</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20100927.0</td>\n",
       "      <td>MIT-2-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20230929.0</td>\n",
       "      <td>USC-32-Z-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>University of Southern California</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20200723.0</td>\n",
       "      <td>WGL-117-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>WFA Group LLC</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aut     changed            org_id source  \\\n",
       "0    1  20240618.0      LPL-141-ARIN   ARIN   \n",
       "1    2  20231108.0  UNIVER-19-Z-ARIN   ARIN   \n",
       "2    3  20100927.0        MIT-2-ARIN   ARIN   \n",
       "3    4  20230929.0     USC-32-Z-ARIN   ARIN   \n",
       "4    5  20200723.0      WGL-117-ARIN   ARIN   \n",
       "\n",
       "                                org_name country  \n",
       "0                    Level 3 Parent, LLC      US  \n",
       "1                 University of Delaware      US  \n",
       "2  Massachusetts Institute of Technology      US  \n",
       "3      University of Southern California      US  \n",
       "4                          WFA Group LLC      US  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "with open('/workspaces/pytorch-gpu-2/preprocessing/data/caida/20251001.as-org2info.txt', 'r', newline='', encoding='utf-8') as input_file:\n",
    "    lines = input_file.readlines()   \n",
    "    # Buffers initialisieren\n",
    "    aut_lines = []\n",
    "    org_lines = []\n",
    "    mode = None\n",
    "    total_lines = len(lines)\n",
    "    aut_count = 0\n",
    "    org_count = 0 \n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"# format:aut\"):\n",
    "            mode = \"aut\"\n",
    "            continue\n",
    "        elif line.startswith(\"# format:org_id\"):\n",
    "            mode = \"org\"\n",
    "            continue\n",
    "        elif line.startswith(\"#\") or not line:\n",
    "            # Andere Kommentar- oder Leerzeilen überspringen\n",
    "            continue      \n",
    "        if mode == \"aut\":\n",
    "            aut_lines.append(line)\n",
    "            aut_count += 1\n",
    "        elif mode == \"org\":\n",
    "            org_lines.append(line)\n",
    "            org_count += 1\n",
    "    # StringIO-Objekte aus den gesammelten Zeilen bauen\n",
    "    aut_buffer = io.StringIO(\"\\n\".join(aut_lines))\n",
    "    org_buffer = io.StringIO(\"\\n\".join(org_lines))\n",
    "    # DataFrames einlesen\n",
    "    aut_df = pd.read_csv(aut_buffer, sep=\"|\",\n",
    "                        names=[\"aut\", \"changed\", \"aut_name\", \"org_id\", \"opaque_id\", \"source\"], usecols=[\"aut\", \"org_id\", \"source\", \"changed\"])\n",
    "    org_df = pd.read_csv(org_buffer, sep=\"|\",\n",
    "                        names=[\"org_id\", \"changed\", \"org_name\", \"country\", \"source\"], usecols=[\"org_id\", \"org_name\", \"country\"])\n",
    "\n",
    "    # Join the DataFrames\n",
    "    joined_df = pd.merge(aut_df, org_df, on=\"org_id\", how=\"left\")\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e5047",
   "metadata": {},
   "source": [
    "## Join both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6de8ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "org_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2ec8bfc7-ba72-48d4-99f9-7c5dbd97b9c6",
       "rows": [
        [
         "0",
         "4436",
         "GTT Americas, LLC",
         "US",
         "ARIN",
         "NSP"
        ],
        [
         "1",
         "20940",
         "Akamai International B.V.",
         "NL",
         "RIPE",
         "Content"
        ],
        [
         "2",
         "31800",
         "DALnet",
         "US",
         "ARIN",
         "Non-Profit"
        ],
        [
         "3",
         "3303",
         "Swisscom (Schweiz) AG",
         "CH",
         "RIPE",
         "Cable/DSL/ISP"
        ],
        [
         "4",
         "22773",
         "Cox Communications Inc.",
         "US",
         "ARIN",
         "Cable/DSL/ISP"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asn</th>\n",
       "      <th>org_name</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>info_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4436</td>\n",
       "      <td>GTT Americas, LLC</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>NSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20940</td>\n",
       "      <td>Akamai International B.V.</td>\n",
       "      <td>NL</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31800</td>\n",
       "      <td>DALnet</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Non-Profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3303</td>\n",
       "      <td>Swisscom (Schweiz) AG</td>\n",
       "      <td>CH</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22773</td>\n",
       "      <td>Cox Communications Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     asn                   org_name country source      info_type\n",
       "0   4436          GTT Americas, LLC      US   ARIN            NSP\n",
       "1  20940  Akamai International B.V.      NL   RIPE        Content\n",
       "2  31800                     DALnet      US   ARIN     Non-Profit\n",
       "3   3303      Swisscom (Schweiz) AG      CH   RIPE  Cable/DSL/ISP\n",
       "4  22773    Cox Communications Inc.      US   ARIN  Cable/DSL/ISP"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peering_df_joined = pd.merge(net_df, joined_df, left_on='asn', right_on='aut', how='left')\n",
    "peering_df_joined = peering_df_joined[['asn', 'org_name', 'country', 'source', 'info_type']]\n",
    "peering_df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99053eb",
   "metadata": {},
   "source": [
    "## Load AS Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e496cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rank",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asnDegree_total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asnDegree_customer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asnDegree_peer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asnDegree_provider",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cone_numberAsns",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cone_numberPrefixes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cone_numberAddresses",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "60403ffd-9638-4f61-ace4-c6ce04197443",
       "rows": [
        [
         "0",
         "3356",
         "1",
         "6613",
         "6545",
         "68",
         "0",
         "53986",
         "873410",
         "3468642119"
        ],
        [
         "1",
         "1299",
         "2",
         "2567",
         "2509",
         "58",
         "0",
         "41193",
         "776707",
         "3219679484"
        ],
        [
         "2",
         "174",
         "3",
         "6723",
         "6626",
         "97",
         "0",
         "38887",
         "730166",
         "3034352967"
        ],
        [
         "3",
         "3257",
         "4",
         "1853",
         "1816",
         "37",
         "0",
         "36040",
         "612491",
         "2791999209"
        ],
        [
         "4",
         "2914",
         "5",
         "1541",
         "1483",
         "58",
         "0",
         "25179",
         "576134",
         "2918763154"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asn</th>\n",
       "      <th>rank</th>\n",
       "      <th>asnDegree_total</th>\n",
       "      <th>asnDegree_customer</th>\n",
       "      <th>asnDegree_peer</th>\n",
       "      <th>asnDegree_provider</th>\n",
       "      <th>cone_numberAsns</th>\n",
       "      <th>cone_numberPrefixes</th>\n",
       "      <th>cone_numberAddresses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3356</td>\n",
       "      <td>1</td>\n",
       "      <td>6613</td>\n",
       "      <td>6545</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>53986</td>\n",
       "      <td>873410</td>\n",
       "      <td>3468642119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1299</td>\n",
       "      <td>2</td>\n",
       "      <td>2567</td>\n",
       "      <td>2509</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>41193</td>\n",
       "      <td>776707</td>\n",
       "      <td>3219679484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174</td>\n",
       "      <td>3</td>\n",
       "      <td>6723</td>\n",
       "      <td>6626</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>38887</td>\n",
       "      <td>730166</td>\n",
       "      <td>3034352967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3257</td>\n",
       "      <td>4</td>\n",
       "      <td>1853</td>\n",
       "      <td>1816</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>36040</td>\n",
       "      <td>612491</td>\n",
       "      <td>2791999209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2914</td>\n",
       "      <td>5</td>\n",
       "      <td>1541</td>\n",
       "      <td>1483</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>25179</td>\n",
       "      <td>576134</td>\n",
       "      <td>2918763154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    asn  rank  asnDegree_total  asnDegree_customer  asnDegree_peer  \\\n",
       "0  3356     1             6613                6545              68   \n",
       "1  1299     2             2567                2509              58   \n",
       "2   174     3             6723                6626              97   \n",
       "3  3257     4             1853                1816              37   \n",
       "4  2914     5             1541                1483              58   \n",
       "\n",
       "   asnDegree_provider  cone_numberAsns  cone_numberPrefixes  \\\n",
       "0                   0            53986               873410   \n",
       "1                   0            41193               776707   \n",
       "2                   0            38887               730166   \n",
       "3                   0            36040               612491   \n",
       "4                   0            25179               576134   \n",
       "\n",
       "   cone_numberAddresses  \n",
       "0            3468642119  \n",
       "1            3219679484  \n",
       "2            3034352967  \n",
       "3            2791999209  \n",
       "4            2918763154  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_rank_df = pd.read_csv('/workspaces/pytorch-gpu-2/preprocessing/data/asrank/as_rank_df.csv')\n",
    "as_rank_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c4fdf",
   "metadata": {},
   "source": [
    "## Join both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498be035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "org_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rank",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "asnDegree_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "asnDegree_customer",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "asnDegree_peer",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "asnDegree_provider",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cone_numberAsns",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cone_numberPrefixes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cone_numberAddresses",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2bbf6465-ddbd-4ad0-b9dd-69e35eee4345",
       "rows": [
        [
         "0",
         "4436",
         "GTT Americas, LLC",
         "US",
         "ARIN",
         "NSP",
         "78320.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "20940",
         "Akamai International B.V.",
         "NL",
         "RIPE",
         "Content",
         "1894.0",
         "485.0",
         "14.0",
         "366.0",
         "105.0",
         "15.0",
         "8945.0",
         "14612752.0"
        ],
        [
         "2",
         "31800",
         "DALnet",
         "US",
         "ARIN",
         "Non-Profit",
         "47745.0",
         "78.0",
         "0.0",
         "74.0",
         "4.0",
         "1.0",
         "2.0",
         "512.0"
        ],
        [
         "3",
         "3303",
         "Swisscom (Schweiz) AG",
         "CH",
         "RIPE",
         "Cable/DSL/ISP",
         "81.0",
         "1273.0",
         "166.0",
         "1101.0",
         "6.0",
         "733.0",
         "22131.0",
         "42899794.0"
        ],
        [
         "4",
         "22773",
         "Cox Communications Inc.",
         "US",
         "ARIN",
         "Cable/DSL/ISP",
         "110.0",
         "499.0",
         "489.0",
         "8.0",
         "2.0",
         "505.0",
         "11982.0",
         "31992440.0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asn</th>\n",
       "      <th>org_name</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>info_type</th>\n",
       "      <th>rank</th>\n",
       "      <th>asnDegree_total</th>\n",
       "      <th>asnDegree_customer</th>\n",
       "      <th>asnDegree_peer</th>\n",
       "      <th>asnDegree_provider</th>\n",
       "      <th>cone_numberAsns</th>\n",
       "      <th>cone_numberPrefixes</th>\n",
       "      <th>cone_numberAddresses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4436</td>\n",
       "      <td>GTT Americas, LLC</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>NSP</td>\n",
       "      <td>78320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20940</td>\n",
       "      <td>Akamai International B.V.</td>\n",
       "      <td>NL</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Content</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8945.0</td>\n",
       "      <td>14612752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31800</td>\n",
       "      <td>DALnet</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>47745.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3303</td>\n",
       "      <td>Swisscom (Schweiz) AG</td>\n",
       "      <td>CH</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>22131.0</td>\n",
       "      <td>42899794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22773</td>\n",
       "      <td>Cox Communications Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "      <td>110.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>11982.0</td>\n",
       "      <td>31992440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     asn                   org_name country source      info_type     rank  \\\n",
       "0   4436          GTT Americas, LLC      US   ARIN            NSP  78320.0   \n",
       "1  20940  Akamai International B.V.      NL   RIPE        Content   1894.0   \n",
       "2  31800                     DALnet      US   ARIN     Non-Profit  47745.0   \n",
       "3   3303      Swisscom (Schweiz) AG      CH   RIPE  Cable/DSL/ISP     81.0   \n",
       "4  22773    Cox Communications Inc.      US   ARIN  Cable/DSL/ISP    110.0   \n",
       "\n",
       "   asnDegree_total  asnDegree_customer  asnDegree_peer  asnDegree_provider  \\\n",
       "0              0.0                 0.0             0.0                 0.0   \n",
       "1            485.0                14.0           366.0               105.0   \n",
       "2             78.0                 0.0            74.0                 4.0   \n",
       "3           1273.0               166.0          1101.0                 6.0   \n",
       "4            499.0               489.0             8.0                 2.0   \n",
       "\n",
       "   cone_numberAsns  cone_numberPrefixes  cone_numberAddresses  \n",
       "0              1.0                  0.0                   0.0  \n",
       "1             15.0               8945.0            14612752.0  \n",
       "2              1.0                  2.0                 512.0  \n",
       "3            733.0              22131.0            42899794.0  \n",
       "4            505.0              11982.0            31992440.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peering_df_joined_with_asrank = pd.merge(\n",
    "    peering_df_joined,\n",
    "    as_rank_df,\n",
    "    left_on='asn',\n",
    "    right_on='asn',\n",
    "    how='left'\n",
    ")\n",
    "peering_df_joined_with_asrank['rank'].fillna(peering_df_joined_with_asrank['rank'].median(), inplace=True)\n",
    "peering_df_joined_with_asrank['asnDegree_total'].fillna(peering_df_joined_with_asrank['asnDegree_total'].median(), inplace=True)\n",
    "peering_df_joined_with_asrank['asnDegree_customer'].fillna(peering_df_joined_with_asrank['asnDegree_customer'].median(), inplace=True)\n",
    "peering_df_joined_with_asrank['asnDegree_peer'].fillna(peering_df_joined_with_asrank['asnDegree_peer'].median(), inplace=True)\n",
    "peering_df_joined_with_asrank['asnDegree_provider'].fillna(peering_df_joined_with_asrank['asnDegree_provider'].median(), inplace=True)\n",
    "peering_df_joined_with_asrank['cone_numberAsns'].fillna(peering_df_joined_with_asrank['cone_numberAsns'].median(), inplace=True)\n",
    "peering_df_joined_with_asrank['cone_numberPrefixes'].fillna(peering_df_joined_with_asrank['cone_numberPrefixes'].median(), inplace=True)\n",
    "peering_df_joined_with_asrank['cone_numberAddresses'].fillna(peering_df_joined_with_asrank['cone_numberAddresses'].median(), inplace=True)\n",
    "\n",
    "peering_df_joined_with_asrank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da8c67",
   "metadata": {},
   "source": [
    "## Load domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d9a971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ASN",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "domains",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "10d06948-e4ec-420a-a4d7-a6671c624764",
       "rows": [
        [
         "0",
         "16509",
         "139276485"
        ],
        [
         "1",
         "13335",
         "63477595"
        ],
        [
         "2",
         "52925",
         "32915972"
        ],
        [
         "3",
         "396982",
         "24543491"
        ],
        [
         "4",
         "47846",
         "17833760"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASN</th>\n",
       "      <th>domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16509</td>\n",
       "      <td>139276485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13335</td>\n",
       "      <td>63477595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52925</td>\n",
       "      <td>32915972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>396982</td>\n",
       "      <td>24543491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47846</td>\n",
       "      <td>17833760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ASN    domains\n",
       "0   16509  139276485\n",
       "1   13335   63477595\n",
       "2   52925   32915972\n",
       "3  396982   24543491\n",
       "4   47846   17833760"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipinfo_df = pd.read_csv('../../preprocessing/data/ipinfo_domains/ipinfo_domains.csv')\n",
    "ipinfo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612c6db",
   "metadata": {},
   "source": [
    "## Join both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c144c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "org_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rank",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "asnDegree_total",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "asnDegree_customer",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "asnDegree_peer",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "asnDegree_provider",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cone_numberAsns",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cone_numberPrefixes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cone_numberAddresses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ASN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "domains",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ee7fd031-b11b-4563-a0c5-427cfe4da88a",
       "rows": [
        [
         "0",
         "4436",
         "GTT Americas, LLC",
         "US",
         "ARIN",
         "NSP",
         "78320.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         null,
         "21.0"
        ],
        [
         "1",
         "20940",
         "Akamai International B.V.",
         "NL",
         "RIPE",
         "Content",
         "1894.0",
         "485.0",
         "14.0",
         "366.0",
         "105.0",
         "15.0",
         "8945.0",
         "14612752.0",
         "20940.0",
         "3849287.0"
        ],
        [
         "2",
         "31800",
         "DALnet",
         "US",
         "ARIN",
         "Non-Profit",
         "47745.0",
         "78.0",
         "0.0",
         "74.0",
         "4.0",
         "1.0",
         "2.0",
         "512.0",
         null,
         "21.0"
        ],
        [
         "3",
         "3303",
         "Swisscom (Schweiz) AG",
         "CH",
         "RIPE",
         "Cable/DSL/ISP",
         "81.0",
         "1273.0",
         "166.0",
         "1101.0",
         "6.0",
         "733.0",
         "22131.0",
         "42899794.0",
         "3303.0",
         "46521.0"
        ],
        [
         "4",
         "22773",
         "Cox Communications Inc.",
         "US",
         "ARIN",
         "Cable/DSL/ISP",
         "110.0",
         "499.0",
         "489.0",
         "8.0",
         "2.0",
         "505.0",
         "11982.0",
         "31992440.0",
         "22773.0",
         "55711.0"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asn</th>\n",
       "      <th>org_name</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>info_type</th>\n",
       "      <th>rank</th>\n",
       "      <th>asnDegree_total</th>\n",
       "      <th>asnDegree_customer</th>\n",
       "      <th>asnDegree_peer</th>\n",
       "      <th>asnDegree_provider</th>\n",
       "      <th>cone_numberAsns</th>\n",
       "      <th>cone_numberPrefixes</th>\n",
       "      <th>cone_numberAddresses</th>\n",
       "      <th>ASN</th>\n",
       "      <th>domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4436</td>\n",
       "      <td>GTT Americas, LLC</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>NSP</td>\n",
       "      <td>78320.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20940</td>\n",
       "      <td>Akamai International B.V.</td>\n",
       "      <td>NL</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Content</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8945.0</td>\n",
       "      <td>14612752.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>3849287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31800</td>\n",
       "      <td>DALnet</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>47745.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3303</td>\n",
       "      <td>Swisscom (Schweiz) AG</td>\n",
       "      <td>CH</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>22131.0</td>\n",
       "      <td>42899794.0</td>\n",
       "      <td>3303.0</td>\n",
       "      <td>46521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22773</td>\n",
       "      <td>Cox Communications Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "      <td>110.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>11982.0</td>\n",
       "      <td>31992440.0</td>\n",
       "      <td>22773.0</td>\n",
       "      <td>55711.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     asn                   org_name country source      info_type     rank  \\\n",
       "0   4436          GTT Americas, LLC      US   ARIN            NSP  78320.0   \n",
       "1  20940  Akamai International B.V.      NL   RIPE        Content   1894.0   \n",
       "2  31800                     DALnet      US   ARIN     Non-Profit  47745.0   \n",
       "3   3303      Swisscom (Schweiz) AG      CH   RIPE  Cable/DSL/ISP     81.0   \n",
       "4  22773    Cox Communications Inc.      US   ARIN  Cable/DSL/ISP    110.0   \n",
       "\n",
       "   asnDegree_total  asnDegree_customer  asnDegree_peer  asnDegree_provider  \\\n",
       "0              0.0                 0.0             0.0                 0.0   \n",
       "1            485.0                14.0           366.0               105.0   \n",
       "2             78.0                 0.0            74.0                 4.0   \n",
       "3           1273.0               166.0          1101.0                 6.0   \n",
       "4            499.0               489.0             8.0                 2.0   \n",
       "\n",
       "   cone_numberAsns  cone_numberPrefixes  cone_numberAddresses      ASN  \\\n",
       "0              1.0                  0.0                   0.0      NaN   \n",
       "1             15.0               8945.0            14612752.0  20940.0   \n",
       "2              1.0                  2.0                 512.0      NaN   \n",
       "3            733.0              22131.0            42899794.0   3303.0   \n",
       "4            505.0              11982.0            31992440.0  22773.0   \n",
       "\n",
       "     domains  \n",
       "0       21.0  \n",
       "1  3849287.0  \n",
       "2       21.0  \n",
       "3    46521.0  \n",
       "4    55711.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peering_df_joined_with_asrank_and_domains = pd.merge(\n",
    "    peering_df_joined_with_asrank,\n",
    "    ipinfo_df,\n",
    "    left_on='asn',\n",
    "    right_on='ASN',\n",
    "    how='left'\n",
    ")\n",
    "peering_df_joined_with_asrank_and_domains['domains'].fillna(peering_df_joined_with_asrank_and_domains['domains'].median(), inplace=True)\n",
    "peering_df_joined_with_asrank_and_domains.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c082156c",
   "metadata": {},
   "source": [
    "## Load geolocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2902187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asn",
         "rawType": "uint64",
         "type": "integer"
        },
        {
         "name": "center_lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "center_lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_weight",
         "rawType": "uint64",
         "type": "integer"
        },
        {
         "name": "unique_points",
         "rawType": "uint64",
         "type": "integer"
        },
        {
         "name": "country_count",
         "rawType": "uint64",
         "type": "integer"
        },
        {
         "name": "mean_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "var_km2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "iqr_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p25_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p50_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p75_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p90_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p95_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p99_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pct_ips_le_100km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pct_ips_le_500km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pct_ips_le_1000km",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b033eff6-9a59-4777-b906-481138653a2a",
       "rows": [
        [
         "0",
         "1",
         "25.968",
         "92.5789",
         "78170880",
         "79",
         "61",
         "244.02",
         "81524.56",
         "285.53",
         "85.42",
         "184.1",
         "202.41",
         "269.52",
         "270.88",
         "323.86",
         "2174.95",
         "22.74",
         "16533.53",
         "14.53",
         "96.74",
         "97.75"
        ],
        [
         "1",
         "2",
         "33.23043",
         "-61.91418",
         "86016",
         "4",
         "4",
         "3182.86",
         "10932427.46",
         "3306.42",
         "0.0",
         "1427.96",
         "1427.96",
         "1427.96",
         "8556.52",
         "11221.18",
         "11221.18",
         "1427.96",
         "11221.18",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "3",
         "42.49447",
         "-76.06584",
         "46607360",
         "21",
         "16",
         "702.31",
         "781753.99",
         "884.17",
         "0.0",
         "411.17",
         "411.17",
         "411.17",
         "1267.02",
         "3902.24",
         "3906.49",
         "227.04",
         "15164.77",
         "0.0",
         "85.21",
         "85.21"
        ],
        [
         "3",
         "4",
         "39.84525",
         "-77.49818",
         "162816",
         "7",
         "6",
         "435.78",
         "3240972.63",
         "1800.27",
         "0.42",
         "112.44",
         "112.86",
         "112.86",
         "112.86",
         "112.86",
         "12790.22",
         "81.32",
         "12790.22",
         "17.61",
         "95.6",
         "95.6"
        ],
        [
         "4",
         "5",
         "36.12522",
         "-113.40178",
         "2304",
         "4",
         "4",
         "1766.67",
         "7530375.89",
         "2744.15",
         "0.33",
         "800.84",
         "801.17",
         "801.17",
         "9527.87",
         "9527.87",
         "9527.87",
         "768.83",
         "9527.87",
         "0.0",
         "0.0",
         "88.89"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asn</th>\n",
       "      <th>center_lat</th>\n",
       "      <th>center_lon</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>unique_points</th>\n",
       "      <th>country_count</th>\n",
       "      <th>mean_km</th>\n",
       "      <th>var_km2</th>\n",
       "      <th>std_km</th>\n",
       "      <th>iqr_km</th>\n",
       "      <th>...</th>\n",
       "      <th>p50_km</th>\n",
       "      <th>p75_km</th>\n",
       "      <th>p90_km</th>\n",
       "      <th>p95_km</th>\n",
       "      <th>p99_km</th>\n",
       "      <th>min_km</th>\n",
       "      <th>max_km</th>\n",
       "      <th>pct_ips_le_100km</th>\n",
       "      <th>pct_ips_le_500km</th>\n",
       "      <th>pct_ips_le_1000km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25.96800</td>\n",
       "      <td>92.57890</td>\n",
       "      <td>78170880</td>\n",
       "      <td>79</td>\n",
       "      <td>61</td>\n",
       "      <td>244.02</td>\n",
       "      <td>81524.56</td>\n",
       "      <td>285.53</td>\n",
       "      <td>85.42</td>\n",
       "      <td>...</td>\n",
       "      <td>202.41</td>\n",
       "      <td>269.52</td>\n",
       "      <td>270.88</td>\n",
       "      <td>323.86</td>\n",
       "      <td>2174.95</td>\n",
       "      <td>22.74</td>\n",
       "      <td>16533.53</td>\n",
       "      <td>14.53</td>\n",
       "      <td>96.74</td>\n",
       "      <td>97.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33.23043</td>\n",
       "      <td>-61.91418</td>\n",
       "      <td>86016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3182.86</td>\n",
       "      <td>10932427.46</td>\n",
       "      <td>3306.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1427.96</td>\n",
       "      <td>1427.96</td>\n",
       "      <td>8556.52</td>\n",
       "      <td>11221.18</td>\n",
       "      <td>11221.18</td>\n",
       "      <td>1427.96</td>\n",
       "      <td>11221.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>42.49447</td>\n",
       "      <td>-76.06584</td>\n",
       "      <td>46607360</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>702.31</td>\n",
       "      <td>781753.99</td>\n",
       "      <td>884.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>411.17</td>\n",
       "      <td>411.17</td>\n",
       "      <td>1267.02</td>\n",
       "      <td>3902.24</td>\n",
       "      <td>3906.49</td>\n",
       "      <td>227.04</td>\n",
       "      <td>15164.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>85.21</td>\n",
       "      <td>85.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39.84525</td>\n",
       "      <td>-77.49818</td>\n",
       "      <td>162816</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>435.78</td>\n",
       "      <td>3240972.63</td>\n",
       "      <td>1800.27</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>112.86</td>\n",
       "      <td>112.86</td>\n",
       "      <td>112.86</td>\n",
       "      <td>112.86</td>\n",
       "      <td>12790.22</td>\n",
       "      <td>81.32</td>\n",
       "      <td>12790.22</td>\n",
       "      <td>17.61</td>\n",
       "      <td>95.60</td>\n",
       "      <td>95.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>36.12522</td>\n",
       "      <td>-113.40178</td>\n",
       "      <td>2304</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1766.67</td>\n",
       "      <td>7530375.89</td>\n",
       "      <td>2744.15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>801.17</td>\n",
       "      <td>801.17</td>\n",
       "      <td>9527.87</td>\n",
       "      <td>9527.87</td>\n",
       "      <td>9527.87</td>\n",
       "      <td>768.83</td>\n",
       "      <td>9527.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>88.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   asn  center_lat  center_lon  total_weight  unique_points  country_count  \\\n",
       "0    1    25.96800    92.57890      78170880             79             61   \n",
       "1    2    33.23043   -61.91418         86016              4              4   \n",
       "2    3    42.49447   -76.06584      46607360             21             16   \n",
       "3    4    39.84525   -77.49818        162816              7              6   \n",
       "4    5    36.12522  -113.40178          2304              4              4   \n",
       "\n",
       "   mean_km      var_km2   std_km  iqr_km  ...   p50_km   p75_km   p90_km  \\\n",
       "0   244.02     81524.56   285.53   85.42  ...   202.41   269.52   270.88   \n",
       "1  3182.86  10932427.46  3306.42    0.00  ...  1427.96  1427.96  8556.52   \n",
       "2   702.31    781753.99   884.17    0.00  ...   411.17   411.17  1267.02   \n",
       "3   435.78   3240972.63  1800.27    0.42  ...   112.86   112.86   112.86   \n",
       "4  1766.67   7530375.89  2744.15    0.33  ...   801.17   801.17  9527.87   \n",
       "\n",
       "     p95_km    p99_km   min_km    max_km  pct_ips_le_100km  pct_ips_le_500km  \\\n",
       "0    323.86   2174.95    22.74  16533.53             14.53             96.74   \n",
       "1  11221.18  11221.18  1427.96  11221.18              0.00              0.00   \n",
       "2   3902.24   3906.49   227.04  15164.77              0.00             85.21   \n",
       "3    112.86  12790.22    81.32  12790.22             17.61             95.60   \n",
       "4   9527.87   9527.87   768.83   9527.87              0.00              0.00   \n",
       "\n",
       "   pct_ips_le_1000km  \n",
       "0              97.75  \n",
       "1               0.00  \n",
       "2              85.21  \n",
       "3              95.60  \n",
       "4              88.89  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clickhouse_connect\n",
    "\n",
    "client = clickhouse_connect.get_client(\n",
    "    host='localhost', port=8123,\n",
    "    username='default', password=''\n",
    ")\n",
    "\n",
    "query = \"\"\"\n",
    "/* Gewichtetes Zentrum und umfangreiche Distanz-Statistiken (Kilometer) */\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        asn,\n",
    "        latitude,\n",
    "        longitude,\n",
    "        country,\n",
    "        toUInt64(ip_end - ip_start + 1) AS w\n",
    "    FROM ip_location_asn\n",
    "    WHERE ip_version = 4\n",
    "      AND origin = 'ipinfo'\n",
    "),\n",
    "vec AS (\n",
    "    SELECT\n",
    "        asn,\n",
    "        sum(w * cos(radians(latitude)) * cos(radians(longitude))) AS X,\n",
    "        sum(w * cos(radians(latitude)) * sin(radians(longitude))) AS Y,\n",
    "        sum(w * sin(radians(latitude)))                           AS Z,\n",
    "        sum(w)                                                    AS W\n",
    "    FROM base\n",
    "    GROUP BY asn\n",
    "),\n",
    "center AS (\n",
    "    SELECT\n",
    "        asn,\n",
    "        degrees(atan2(Y, X))                       AS center_lon,\n",
    "        degrees(atan2(Z, sqrt(X * X + Y * Y)))     AS center_lat\n",
    "    FROM vec\n",
    "),\n",
    "joined AS (\n",
    "    SELECT\n",
    "        b.asn,\n",
    "        b.w,\n",
    "        b.country,\n",
    "        c.center_lat,\n",
    "        c.center_lon,\n",
    "        greatCircleDistance(b.longitude, b.latitude, c.center_lon, c.center_lat) / 1000 AS d_km\n",
    "    FROM base AS b\n",
    "    INNER JOIN center AS c USING (asn)\n",
    "),\n",
    "stats AS (\n",
    "    SELECT\n",
    "        asn,\n",
    "        any(center_lat) AS center_lat,\n",
    "        any(center_lon) AS center_lon,\n",
    "        sum(w)  AS total_weight,\n",
    "        avgWeighted(d_km,       w) AS mean_km,\n",
    "        avgWeighted(d_km * d_km, w) AS mean_sq_km2,\n",
    "        quantileExactWeighted(0.25)(d_km, w) AS p25_km,\n",
    "        quantileExactWeighted(0.50)(d_km, w) AS p50_km,\n",
    "        quantileExactWeighted(0.75)(d_km, w) AS p75_km,\n",
    "        quantileExactWeighted(0.90)(d_km, w) AS p90_km,\n",
    "        quantileExactWeighted(0.95)(d_km, w) AS p95_km,\n",
    "        quantileExactWeighted(0.99)(d_km, w) AS p99_km,\n",
    "        min(d_km) AS min_km,\n",
    "        max(d_km) AS max_km,\n",
    "        sumIf(w, d_km <=  100) / sum(w) AS share_le_100km,\n",
    "        sumIf(w, d_km <=  500) / sum(w) AS share_le_500km,\n",
    "        sumIf(w, d_km <= 1000) / sum(w) AS share_le_1000km\n",
    "    FROM joined\n",
    "    GROUP BY asn\n",
    "),\n",
    "geo_meta AS (\n",
    "    SELECT\n",
    "        asn,\n",
    "        uniqExact((latitude, longitude)) AS unique_points,\n",
    "        uniqExact(country)               AS country_count\n",
    "    FROM base\n",
    "    GROUP BY asn\n",
    ")\n",
    "SELECT\n",
    "    s.asn,\n",
    "    round(s.center_lat, 5) AS center_lat,\n",
    "    round(s.center_lon, 5) AS center_lon,\n",
    "    s.total_weight,\n",
    "    gm.unique_points,\n",
    "    gm.country_count,\n",
    "    round(s.mean_km, 2)                         AS mean_km,\n",
    "    round(greatest(s.mean_sq_km2 - s.mean_km * s.mean_km, 0), 2) AS var_km2,\n",
    "    round(sqrt(greatest(s.mean_sq_km2 - s.mean_km * s.mean_km, 0)), 2) AS std_km,\n",
    "    round(s.p75_km - s.p25_km, 2)               AS iqr_km,\n",
    "    round(s.p25_km, 2)                          AS p25_km,\n",
    "    round(s.p50_km, 2)                          AS p50_km,\n",
    "    round(s.p75_km, 2)                          AS p75_km,\n",
    "    round(s.p90_km, 2)                          AS p90_km,\n",
    "    round(s.p95_km, 2)                          AS p95_km,\n",
    "    round(s.p99_km, 2)                          AS p99_km,\n",
    "    round(s.min_km, 2)                          AS min_km,\n",
    "    round(s.max_km, 2)                          AS max_km,\n",
    "    round(s.share_le_100km * 100, 2)            AS pct_ips_le_100km,\n",
    "    round(s.share_le_500km * 100, 2)            AS pct_ips_le_500km,\n",
    "    round(s.share_le_1000km * 100, 2)           AS pct_ips_le_1000km\n",
    "FROM stats AS s\n",
    "LEFT JOIN geo_meta AS gm USING (asn)\n",
    "ORDER BY asn\n",
    "\"\"\"\n",
    "\n",
    "ch_df = client.query_df(query)\n",
    "ch_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a528804",
   "metadata": {},
   "source": [
    "## Join both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb447ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asn',\n",
       " 'org_name',\n",
       " 'country',\n",
       " 'source',\n",
       " 'info_type',\n",
       " 'rank',\n",
       " 'asnDegree_total',\n",
       " 'asnDegree_customer',\n",
       " 'asnDegree_peer',\n",
       " 'asnDegree_provider',\n",
       " 'cone_numberAsns',\n",
       " 'cone_numberPrefixes',\n",
       " 'cone_numberAddresses',\n",
       " 'ASN',\n",
       " 'domains',\n",
       " 'center_lat',\n",
       " 'center_lon',\n",
       " 'total_weight',\n",
       " 'unique_points',\n",
       " 'country_count',\n",
       " 'mean_km',\n",
       " 'var_km2',\n",
       " 'std_km',\n",
       " 'iqr_km',\n",
       " 'p25_km',\n",
       " 'p50_km',\n",
       " 'p75_km',\n",
       " 'p90_km',\n",
       " 'p95_km',\n",
       " 'p99_km',\n",
       " 'min_km',\n",
       " 'max_km',\n",
       " 'pct_ips_le_100km',\n",
       " 'pct_ips_le_500km',\n",
       " 'pct_ips_le_1000km']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peering_df_joined_with_asrank_and_domains_and_geoloc = pd.merge(\n",
    "    peering_df_joined_with_asrank_and_domains,\n",
    "    ch_df,\n",
    "    left_on='asn',\n",
    "    right_on='asn',\n",
    "    how='left'\n",
    ")\n",
    "peering_df_joined_with_asrank_and_domains_and_geoloc['org_name'] = peering_df_joined_with_asrank_and_domains_and_geoloc['org_name'].fillna('unknown').str.lower()\n",
    "peering_df_joined_with_asrank_and_domains_and_geoloc.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42bafc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_type",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f9ac6b2a-de47-43ed-98ef-906edaa80a9e",
       "rows": [
        [
         "Access",
         "12561"
        ],
        [
         "Transit",
         "4166"
        ],
        [
         "Enterprise",
         "2575"
        ],
        [
         "Content",
         "2540"
        ],
        [
         "Education/Research",
         "1529"
        ],
        [
         "Network Services",
         "1504"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "Access                12561\n",
       "Transit                4166\n",
       "Enterprise             2575\n",
       "Content                2540\n",
       "Education/Research     1529\n",
       "Network Services       1504\n",
       "Name: info_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_map = {\n",
    "    \"NSP\": \"Transit\",\n",
    "    \"Content\": \"Content\",\n",
    "    \"Cable/DSL/ISP\": \"Access\",\n",
    "    \"Enterprise\": \"Enterprise\",\n",
    "    \"Educational/Research\": \"Education/Research\",\n",
    "    \"Non-Profit\": \"Enterprise\",\n",
    "    \"Government\": \"Enterprise\",\n",
    "    \"Route Server\": \"Network Services\",\n",
    "    \"Route Collector\": \"Network Services\",\n",
    "    \"Network Services\": \"Network Services\",\n",
    "    \"Not-Disclosed\": \"Unknown\"\n",
    "}\n",
    "\n",
    "peering_df_joined_with_asrank_and_domains_and_geoloc[\"info_type\"] = (\n",
    "    peering_df_joined_with_asrank_and_domains_and_geoloc[\"info_type\"]\n",
    "    .map(category_map)\n",
    "    .fillna(peering_df_joined_with_asrank_and_domains_and_geoloc[\"info_type\"])\n",
    ")\n",
    "peering_df_joined_with_asrank_and_domains_and_geoloc[\"info_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbbfeb",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565817d",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce41b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM (calibrated) ===\n",
      "Accuracy: 0.6004947433518862\n",
      "Macro-F1: 0.4486005064207326\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Access       0.64      0.91      0.75      1633\n",
      "           Content       0.45      0.31      0.36       330\n",
      "Education/Research       0.66      0.48      0.56       199\n",
      "        Enterprise       0.53      0.32      0.40       335\n",
      "  Network Services       0.64      0.25      0.36       195\n",
      "           Transit       0.41      0.20      0.27       542\n",
      "\n",
      "          accuracy                           0.60      3234\n",
      "         macro avg       0.56      0.41      0.45      3234\n",
      "      weighted avg       0.57      0.60      0.56      3234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# ==== Daten ====\n",
    "df = peering_df_joined_with_asrank_and_domains_and_geoloc.copy()\n",
    "df[\"org_name\"] = df[\"org_name\"].fillna(\"unknown\").str.lower()\n",
    "valid = df[\"info_type\"].value_counts()\n",
    "df = df[df[\"info_type\"].isin(valid[valid >= 5].index)]  # sehr kleine Klassen raus (optional)\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df[\"org_name\"], df[\"info_type\"], test_size=0.13, random_state=42, stratify=df[\"info_type\"]\n",
    ")\n",
    "\n",
    "# Gemeinsamer Vectorizer (fit nur auf Train!)\n",
    "vec = TfidfVectorizer(analyzer=\"char\", ngram_range=(1,6),\n",
    "                      lowercase=True, min_df=1, sublinear_tf=True)\n",
    "\n",
    "# ==== 1) SVM + Kalibrierung ====\n",
    "svm = LinearSVC(C=0.35, class_weight=\"balanced\")\n",
    "svm_cal = CalibratedClassifierCV(svm, method=\"sigmoid\", cv=3)\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    (\"tfidf\", vec),\n",
    "    (\"svm_cal\", svm_cal)\n",
    "])\n",
    "\n",
    "svm_pipe.fit(X_train_text, y_train)\n",
    "y_pred_svm = svm_pipe.predict(X_test_text)\n",
    "print(\"\\n=== SVM (calibrated) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_svm, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a706a136",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "310a1d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TF-IDF(Text) + Numerik -> Calibrated LinearSVC ===\n",
      "Accuracy: 0.6360544217687075\n",
      "Macro-F1: 0.5344013616071771\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Access       0.76      0.81      0.79      1633\n",
      "           Content       0.45      0.52      0.48       330\n",
      "Education/Research       0.61      0.63      0.62       199\n",
      "        Enterprise       0.47      0.44      0.46       335\n",
      "  Network Services       0.42      0.44      0.43       195\n",
      "           Transit       0.52      0.37      0.43       542\n",
      "\n",
      "          accuracy                           0.64      3234\n",
      "         macro avg       0.54      0.54      0.53      3234\n",
      "      weighted avg       0.63      0.64      0.63      3234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === TF-IDF (org_name) + Numerik -> Calibrated LinearSVC ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# ---------- Daten vorbereiten ----------\n",
    "df = peering_df_joined_with_asrank_and_domains_and_geoloc.copy()\n",
    "\n",
    "# Text normalisieren\n",
    "df[\"org_name\"] = df[\"org_name\"].fillna(\"unknown\").astype(str).str.lower()\n",
    "\n",
    "# Sehr kleine Klassen optional rausfiltern\n",
    "valid = df[\"info_type\"].value_counts()\n",
    "df = df[df[\"info_type\"].isin(valid[valid >= 5].index)].reset_index(drop=True)\n",
    "\n",
    "# Zielspalte\n",
    "y = df[\"info_type\"].astype(str)\n",
    "\n",
    "# Numerische Spalten bestimmen (alles außer Text/Kat/Label)\n",
    "ignore = {\"org_name\", \"info_type\", \"country\", \"source\"}\n",
    "num_candidates = [c for c in df.columns if c not in ignore]\n",
    "\n",
    "# Nur numerisch verwertbare Spalten (coerce -> float)\n",
    "num_df = df[num_candidates].apply(pd.to_numeric, errors=\"coerce\")\n",
    "num_df = num_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "num_cols = num_df.columns.tolist()\n",
    "\n",
    "# Feature-DataFrame für Pipeline\n",
    "X = pd.concat([df[[\"org_name\"]].reset_index(drop=True),\n",
    "               num_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# ---------- Train/Test Split ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.13, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---------- Preprocessing ----------\n",
    "def log1p_array(A):\n",
    "    A = np.asarray(A, dtype=float)\n",
    "    A = np.clip(A, a_min=0.0, a_max=None)\n",
    "    return np.log1p(A)\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"log1p\", FunctionTransformer(log1p_array, validate=True)),\n",
    "    (\"scale\", MaxAbsScaler())\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", TfidfVectorizer(analyzer=\"char\", ngram_range=(2,6),\n",
    "                                 lowercase=True, sublinear_tf=True, min_df=1),\n",
    "         \"org_name\"),\n",
    "        (\"num\",  num_pipe, num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "# ---------- SVM + Kalibrierung ----------\n",
    "base_svm = LinearSVC(C=0.35, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"svm\", base_svm)\n",
    "])\n",
    "\n",
    "# ---------- Trainieren ----------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ---------- Evaluieren ----------\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"\\n=== TF-IDF(Text) + Numerik -> Calibrated LinearSVC ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# ---------- (Optional) Probas für Ensembling ----------\n",
    "# P_test = pipe.predict_proba(X_test)   # shape [N, n_classes]\n",
    "# classes_ = pipe.named_steps[\"svm\"].classes_.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca5a40ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LinearSVC (TF-IDF + Numerik + country) ===\n",
      "Accuracy: 0.6499690785405071\n",
      "Macro-F1: 0.5470150591016102\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Access       0.78      0.82      0.80      1633\n",
      "           Content       0.46      0.55      0.50       330\n",
      "Education/Research       0.62      0.59      0.61       199\n",
      "        Enterprise       0.51      0.48      0.49       335\n",
      "  Network Services       0.41      0.44      0.42       195\n",
      "           Transit       0.53      0.41      0.46       542\n",
      "\n",
      "          accuracy                           0.65      3234\n",
      "         macro avg       0.55      0.55      0.55      3234\n",
      "      weighted avg       0.65      0.65      0.65      3234\n",
      "\n",
      "\n",
      "=== SGD(modified_huber) (TF-IDF + Numerik + country) ===\n",
      "Accuracy: 0.5714285714285714\n",
      "Macro-F1: 0.48382855621293547\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Access       0.81      0.69      0.75      1633\n",
      "           Content       0.60      0.25      0.35       330\n",
      "Education/Research       0.70      0.45      0.55       199\n",
      "        Enterprise       0.62      0.29      0.40       335\n",
      "  Network Services       0.53      0.38      0.44       195\n",
      "           Transit       0.29      0.69      0.41       542\n",
      "\n",
      "          accuracy                           0.57      3234\n",
      "         macro avg       0.59      0.46      0.48      3234\n",
      "      weighted avg       0.66      0.57      0.58      3234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# TF-IDF (org_name) + Numerik + country\n",
    "# -> LinearSVC (unkalibriert)  und  SGD(modified_huber, mit Probas)\n",
    "# ===============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def amplify_numeric(X, factor=3.0):\n",
    "    return X * factor\n",
    "\n",
    "# ==== 0) Quelle laden (passe ggf. den DF-Namen an) ====\n",
    "df = peering_df_joined_with_asrank_and_domains_and_geoloc.copy()\n",
    "\n",
    "# ==== 1) Vorverarbeitung & Label-Filter ====\n",
    "df[\"org_name\"] = df[\"org_name\"].fillna(\"unknown\").astype(str).str.lower()\n",
    "valid = df[\"info_type\"].value_counts()\n",
    "df = df[df[\"info_type\"].isin(valid[valid >= 5].index)].reset_index(drop=True)\n",
    "\n",
    "# Ziel\n",
    "y = df[\"info_type\"].astype(str)\n",
    "\n",
    "# ==== 2) Feature-Spalten bestimmen ====\n",
    "# Wir nehmen country dazu (starkes Signal) und alle numerisch konvertierbaren Spalten\n",
    "ignore = {\"org_name\", \"info_type\", \"source\"}  # 'country' NICHT ignorieren\n",
    "all_cols = df.columns.tolist()\n",
    "text_col = \"org_name\"\n",
    "cat_cols  = [\"country\"] if \"country\" in df.columns else []\n",
    "\n",
    "# numerische Kandidaten = alles außer Text/Label/Source/country\n",
    "num_candidates = [c for c in all_cols if c not in ignore.union({text_col}).union(set(cat_cols))]\n",
    "num_df = df[num_candidates].apply(pd.to_numeric, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "num_cols = num_df.columns.tolist()\n",
    "\n",
    "# Endgültiges X-DF\n",
    "X = pd.concat([df[[text_col] + cat_cols].reset_index(drop=True),\n",
    "               num_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# ==== 3) Train/Test Split ====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.13, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ==== 4) Preprocessor bauen ====\n",
    "# Numerik: Impute -> log1p -> MaxAbsScaler (gut in Kombi mit TF-IDF, bleibt sparse-freundlich)\n",
    "def log1p_array(A):\n",
    "    A = np.asarray(A, dtype=float)\n",
    "    A = np.where(np.isfinite(A), A, np.nan)\n",
    "    # Median-Imputation passiert vorher; hier nur Sicherung\n",
    "    A = np.clip(A, a_min=0.0, a_max=None)\n",
    "    return np.log1p(A)\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"log1p\", FunctionTransformer(log1p_array, validate=True)),\n",
    "    (\"scale\", MaxAbsScaler()),\n",
    "    (\"boost\", FunctionTransformer(lambda X: X * 3.0, validate=False)),  # Gewichtung!\n",
    "])\n",
    "\n",
    "transformers = [\n",
    "    (\"text\", TfidfVectorizer(analyzer=\"char\", ngram_range=(2,6),\n",
    "                             lowercase=True, sublinear_tf=True, min_df=1), text_col),\n",
    "]\n",
    "if cat_cols:\n",
    "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols))\n",
    "if num_cols:\n",
    "    transformers.append((\"num\", num_pipe, num_cols))\n",
    "\n",
    "pre = ColumnTransformer(transformers, remainder=\"drop\", sparse_threshold=0.3)\n",
    "\n",
    "# ==== 5) MODELL A: LinearSVC (unkalibriert) ====\n",
    "svm_linear = LinearSVC(\n",
    "    C=0.35,\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=5000,          # Konvergenz sichern\n",
    "    random_state=42\n",
    ")\n",
    "pipe_svm = Pipeline([(\"pre\", pre), (\"clf\", svm_linear)])\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = pipe_svm.predict(X_test)\n",
    "print(\"\\n=== LinearSVC (TF-IDF + Numerik + country) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_svm, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_svm, zero_division=0))\n",
    "\n",
    "# ==== 6) MODELL B: SGDClassifier (modified_huber) -> liefert predict_proba ====\n",
    "sgd = SGDClassifier(\n",
    "    loss=\"modified_huber\",   # SVM-ähnlich, aber mit Probas\n",
    "    alpha=1e-4,\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=5000,\n",
    "    tol=1e-3,\n",
    "    random_state=42\n",
    ")\n",
    "pipe_sgd = Pipeline([(\"pre\", pre), (\"clf\", sgd)])\n",
    "pipe_sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred_sgd = pipe_sgd.predict(X_test)\n",
    "print(\"\\n=== SGD(modified_huber) (TF-IDF + Numerik + country) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_sgd))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_sgd, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_sgd, zero_division=0))\n",
    "\n",
    "# Optional: Probas (für Ensembling/Routing)\n",
    "# P_test = pipe_sgd.predict_proba(X_test)\n",
    "# classes_ = pipe_sgd.named_steps[\"clf\"].classes_.tolist()\n",
    "\n",
    "# ==== 7) Mini-Tuning (optional, schnell) ====\n",
    "# Wenn du noch 2-3 Punkte rausholen willst, probier leicht andere C/alpha:\n",
    "#   - LinearSVC: C in [0.25, 0.35, 0.5, 0.75, 1.0]\n",
    "#   - SGD alpha in [5e-5, 1e-4, 2e-4]\n",
    "# Oder n-gram Range auf (2,7) testen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87acba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- schnelle & stabile Pipeline ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "df = peering_df_joined_with_asrank_and_domains_and_geoloc.copy()\n",
    "\n",
    "# Labels filtern\n",
    "df[\"org_name\"] = df[\"org_name\"].fillna(\"unknown\").astype(str).str.lower()\n",
    "valid = df[\"info_type\"].value_counts()\n",
    "df = df[df[\"info_type\"].isin(valid[valid >= 5].index)].reset_index(drop=True)\n",
    "y = df[\"info_type\"].astype(str)\n",
    "\n",
    "# Spalten\n",
    "ignore = {\"org_name\", \"info_type\", \"source\"}\n",
    "text_col = \"org_name\"\n",
    "cat_cols  = [\"country\"] if \"country\" in df.columns else []\n",
    "num_candidates = [c for c in df.columns if c not in ignore.union({text_col}).union(set(cat_cols))]\n",
    "num_df = df[num_candidates].apply(pd.to_numeric, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "num_cols = num_df.columns.tolist()\n",
    "\n",
    "X = pd.concat([df[[text_col] + cat_cols].reset_index(drop=True),\n",
    "               num_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.13, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "def log1p_array(A):\n",
    "    A = np.asarray(A, dtype=float)\n",
    "    A = np.where(np.isfinite(A), A, np.nan)\n",
    "    A = np.clip(A, 0.0, None)\n",
    "    return np.log1p(A)\n",
    "\n",
    "# Numerik (klein → darf dicht sein)\n",
    "NUM_BOOST = 8.0\n",
    "num_pipe = Pipeline([\n",
    "    (\"imp\",   SimpleImputer(strategy=\"median\")),\n",
    "    (\"log1p\", FunctionTransformer(log1p_array, validate=True)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"boost\", FunctionTransformer(lambda X: X * NUM_BOOST, validate=False)),\n",
    "])\n",
    "\n",
    "# Text: TF-IDF → SVD (SVD reduziert massiv! DANN ist Dichte ok)\n",
    "text_pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        analyzer=\"char\", ngram_range=(2, 6),\n",
    "        lowercase=True, sublinear_tf=True,\n",
    "        min_df=3,          # etwas strenger für Speed\n",
    "        dtype=np.float32\n",
    "    )),\n",
    "    (\"svd\", TruncatedSVD(n_components=350, random_state=42, n_iter=5)),\n",
    "])\n",
    "\n",
    "# Country: OHE (wenig Kardinalität → dicht ok)\n",
    "try:\n",
    "    cat_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    cat_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "transformers = [(\"text\", text_pipe, text_col)]\n",
    "if cat_cols: transformers.append((\"cat\", cat_encoder, cat_cols))\n",
    "if num_cols: transformers.append((\"num\", num_pipe, num_cols))\n",
    "\n",
    "# WICHTIG: KEIN sparse_threshold=0.0 -> nichts wird unnötig verdichtet\n",
    "pre = ColumnTransformer(transformers, remainder=\"drop\")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    solver=\"saga\",\n",
    "    penalty=\"l2\",\n",
    "    C=2.0,\n",
    "    max_iter=4000,               # dank SVD meist ausreichend\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    multi_class=\"multinomial\",\n",
    ")\n",
    "\n",
    "pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"\\n=== Fast LogisticRegression (TFIDF->SVD + OHE + Num[boost]) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24c3cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Nur Numerik -> HistGradientBoosting ===\n",
      "Accuracy: 0.44712430426716143\n",
      "Macro-F1: 0.26504239987683176\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Cable/DSL/ISP       0.81      0.55      0.66      1633\n",
      "             Content       0.41      0.39      0.40       330\n",
      "Educational/Research       0.30      0.25      0.27       199\n",
      "          Enterprise       0.23      0.25      0.24       233\n",
      "          Government       0.05      0.28      0.08        18\n",
      "                 NSP       0.40      0.32      0.36       542\n",
      "    Network Services       0.10      0.18      0.13       110\n",
      "          Non-Profit       0.18      0.33      0.23        84\n",
      "     Route Collector       0.00      0.00      0.00         4\n",
      "        Route Server       0.16      0.93      0.28        81\n",
      "\n",
      "            accuracy                           0.45      3234\n",
      "           macro avg       0.26      0.35      0.27      3234\n",
      "        weighted avg       0.57      0.45      0.49      3234\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 109\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# ---------- 8) (Optional) Feature-Importance per Permutation ----------\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Hinweis: kann etwas dauern; zeigt dir, welche Numerik-Spalten wirklich tragen.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[0;32m--> 109\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# ColumnTransformer erzeugt eine kombinierte Featureliste:\u001b[39;00m\n\u001b[1;32m    111\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/inspection/_permutation_importance.py:259\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    255\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m _MultimetricScorer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscorers_dict)\n\u001b[1;32m    257\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[0;32m--> 259\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calculate_permutation_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    276\u001b[0m         name: _create_importances_bunch(\n\u001b[1;32m    277\u001b[0m             baseline_score[name],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_score\n\u001b[1;32m    282\u001b[0m     }\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/inspection/_permutation_importance.py:64\u001b[0m, in \u001b[0;36m_calculate_permutation_scores\u001b[0;34m(estimator, X, y, sample_weight, col_idx, random_state, n_repeats, scorer, max_samples)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m         X_permuted[:, col_idx] \u001b[38;5;241m=\u001b[39m X_permuted[shuffling_idx, col_idx]\n\u001b[0;32m---> 64\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_weights_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_permuted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scores[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     67\u001b[0m     scores \u001b[38;5;241m=\u001b[39m _aggregate_score_dicts(scores)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/inspection/_permutation_importance.py:19\u001b[0m, in \u001b[0;36m_weights_scorer\u001b[0;34m(scorer, estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(estimator, X, y, sample_weight)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py:430\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_passthrough_scorer\u001b[39m(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py:723\u001b[0m, in \u001b[0;36mPipeline.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    722\u001b[0m     score_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 723\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py:638\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1874\u001b[0m, in \u001b[0;36mHistGradientBoostingClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict classes for X.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \n\u001b[1;32m   1863\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;124;03m    The predicted classes.\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;66;03m# TODO: This could be done in parallel\u001b[39;00m\n\u001b[0;32m-> 1874\u001b[0m encoded_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[encoded_classes]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1912\u001b[0m, in \u001b[0;36mHistGradientBoostingClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m   1900\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class probabilities for X.\u001b[39;00m\n\u001b[1;32m   1901\u001b[0m \n\u001b[1;32m   1902\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;124;03m        The class probabilities of the input samples.\u001b[39;00m\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1912\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mpredict_proba(raw_predictions)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1043\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._raw_predict\u001b[0;34m(self, X, n_threads)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# We intentionally decouple the number of threads used at prediction\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# time from the number of threads used at fit time because the model\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# can be deployed on a different machine for prediction purposes.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m n_threads \u001b[38;5;241m=\u001b[39m _openmp_effective_n_threads(n_threads)\n\u001b[0;32m-> 1043\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_iterations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_binned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m raw_predictions\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1071\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._predict_iterations\u001b[0;34m(self, X, predictors, raw_predictions, is_binned, n_threads)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     predict \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m   1066\u001b[0m         predictor\u001b[38;5;241m.\u001b[39mpredict,\n\u001b[1;32m   1067\u001b[0m         known_cat_bitsets\u001b[38;5;241m=\u001b[39mknown_cat_bitsets,\n\u001b[1;32m   1068\u001b[0m         f_idx_map\u001b[38;5;241m=\u001b[39mf_idx_map,\n\u001b[1;32m   1069\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m   1070\u001b[0m     )\n\u001b[0;32m-> 1071\u001b[0m raw_predictions[:, k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_hist_gradient_boosting/predictor.py:69\u001b[0m, in \u001b[0;36mTreePredictor.predict\u001b[0;34m(self, X, known_cat_bitsets, f_idx_map, n_threads)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict raw values for non-binned data.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    The raw predicted values.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mY_DTYPE)\n\u001b[0;32m---> 69\u001b[0m \u001b[43m_predict_from_raw_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_left_cat_bitsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_cat_bitsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf_idx_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === Nur Numerik -> HistGradientBoostingClassifier (mit Log1p für schiefe Spalten) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# ---------- 1) Daten vorbereiten ----------\n",
    "# Nimm den gleichen DF wie in deinen letzten Läufen:\n",
    "df = peering_df_joined_with_asrank_and_domains_and_geoloc.copy()\n",
    "\n",
    "# Optional: sehr kleine Klassen entfernen (wie zuvor)\n",
    "valid = df[\"info_type\"].value_counts()\n",
    "df = df[df[\"info_type\"].isin(valid[valid >= 5].index)].reset_index(drop=True)\n",
    "\n",
    "# Ziel\n",
    "y = df[\"info_type\"].astype(str)\n",
    "\n",
    "# Kandidaten für Numerik: alles außer offensichtlichem Text/Kat/Label\n",
    "ignore = {\"org_name\", \"info_type\", \"country\", \"source\"}\n",
    "num_candidates = [c for c in df.columns if c not in ignore]\n",
    "num_candidates.remove(\"asn\")  # ASN ist numerisch, aber keine sinnvolle Zahl\n",
    "\n",
    "# In numerisch zwingen; Unendlichkeiten -> NaN\n",
    "num_df = df[num_candidates].apply(pd.to_numeric, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Falls Spalten komplett NaN sind, droppen\n",
    "num_df = num_df.drop(columns=num_df.columns[num_df.isna().all()], errors=\"ignore\")\n",
    "\n",
    "# Endgültige Numerik-Spaltenliste\n",
    "num_cols = num_df.columns.tolist()\n",
    "\n",
    "# Feature-DF\n",
    "X = num_df.copy()\n",
    "\n",
    "# ---------- 2) Split ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.13, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ---------- 3) Spalten in log/linear trennen ----------\n",
    "# Log1p nur für Spalten, die (nach Imputation) nichtnegativ sind\n",
    "# Wir schätzen die Nichtnegativität vorab grob über die Trainingsdaten (NaN -> 0 für Prüfung)\n",
    "_train_tmp = X_train.copy()\n",
    "_train_tmp = _train_tmp.fillna(0)\n",
    "log_cols = [c for c in _train_tmp.columns if _train_tmp[c].min() >= 0.0]\n",
    "lin_cols = [c for c in _train_tmp.columns if c not in log_cols]\n",
    "\n",
    "def log1p_array(A):\n",
    "    A = np.asarray(A, dtype=float)\n",
    "    # A kommt nach Imputation; zur Sicherheit clippen\n",
    "    A = np.clip(A, a_min=0.0, a_max=None)\n",
    "    return np.log1p(A)\n",
    "\n",
    "# ---------- 4) Preprocessing ----------\n",
    "num_log_pipe = Pipeline([\n",
    "    (\"imp\",   SimpleImputer(strategy=\"median\")),\n",
    "    (\"log1p\", FunctionTransformer(log1p_array, validate=True)),\n",
    "    (\"sc\",    StandardScaler(with_mean=False)),\n",
    "])\n",
    "\n",
    "num_lin_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"sc\",  StandardScaler(with_mean=False)),\n",
    "])\n",
    "\n",
    "transformers = []\n",
    "if log_cols:\n",
    "    transformers.append((\"num_log\", num_log_pipe, log_cols))\n",
    "if lin_cols:\n",
    "    transformers.append((\"num_lin\", num_lin_pipe, lin_cols))\n",
    "\n",
    "pre = ColumnTransformer(transformers, remainder=\"drop\")\n",
    "\n",
    "# ---------- 5) Modell ----------\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.06,\n",
    "    max_leaf_nodes=31,\n",
    "    min_samples_leaf=20,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", hgb)\n",
    "])\n",
    "\n",
    "# ---------- 6) Train ----------\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ---------- 7) Eval ----------\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"\\n=== Nur Numerik -> HistGradientBoosting ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# ---------- 8) (Optional) Feature-Importance per Permutation ----------\n",
    "# Hinweis: kann etwas dauern; zeigt dir, welche Numerik-Spalten wirklich tragen.\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "res = permutation_importance(pipe, X_test, y_test, n_repeats=5, random_state=42)\n",
    "# ColumnTransformer erzeugt eine kombinierte Featureliste:\n",
    "feature_names = []\n",
    "if log_cols:\n",
    "    feature_names += [f\"[log] {c}\" for c in log_cols]\n",
    "if lin_cols:\n",
    "    feature_names += [f\"[lin] {c}\" for c in lin_cols]\n",
    "\n",
    "imp = pd.Series(res.importances_mean, index=feature_names).sort_values(ascending=False)\n",
    "print(\"\\nTop-20 Numerik-Features (Permutation Importance):\")\n",
    "print(imp.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f31e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# TF-IDF (org_name) + Numerik + country\n",
    "# -> LinearSVC (unkalibriert)  und  SGD(modified_huber, mit Probas)\n",
    "# == Numerik gezielt boosten + Wirkung prüfen\n",
    "# ===============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# ==== 0) Quelle laden ====\n",
    "df = peering_df_joined_with_asrank_and_domains_and_geoloc.copy()\n",
    "\n",
    "# ==== 1) Vorverarbeitung & Label-Filter ====\n",
    "df[\"org_name\"] = df[\"org_name\"].fillna(\"unknown\").astype(str).str.lower()\n",
    "valid = df[\"info_type\"].value_counts()\n",
    "df = df[df[\"info_type\"].isin(valid[valid >= 5].index)].reset_index(drop=True)\n",
    "\n",
    "y = df[\"info_type\"].astype(str)\n",
    "\n",
    "# ==== 2) Feature-Spalten ====\n",
    "ignore = {\"org_name\", \"info_type\", \"source\"}  # 'country' NICHT ignorieren\n",
    "all_cols = df.columns.tolist()\n",
    "text_col = \"org_name\"\n",
    "cat_cols  = [\"country\"] if \"country\" in df.columns else []\n",
    "\n",
    "num_candidates = [c for c in all_cols if c not in ignore.union({text_col}).union(set(cat_cols))]\n",
    "num_df = df[num_candidates].apply(pd.to_numeric, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "num_cols = num_df.columns.tolist()\n",
    "\n",
    "X = pd.concat([df[[text_col] + cat_cols].reset_index(drop=True),\n",
    "               num_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# ==== 3) Split ====\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.13, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ==== 4) Preprocessor ====\n",
    "def log1p_array(A):\n",
    "    A = np.asarray(A, dtype=float)\n",
    "    A = np.where(np.isfinite(A), A, np.nan)\n",
    "    A = np.clip(A, a_min=0.0, a_max=None)\n",
    "    return np.log1p(A)\n",
    "\n",
    "# >>> EINZIGER KNOPF: Boost-Faktor für Numerik <<<\n",
    "NUM_BOOST = 8.0   # typ. 5–15 probieren; 8 ist guter Start\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imp\",   SimpleImputer(strategy=\"median\")),\n",
    "    (\"log1p\", FunctionTransformer(log1p_array, validate=True)),\n",
    "    (\"scale\", MaxAbsScaler()),                             # sparse-freundlich\n",
    "    (\"boost\", FunctionTransformer(lambda X: X * NUM_BOOST, # hier boosten!\n",
    "                                  validate=False)),\n",
    "])\n",
    "\n",
    "# OneHotEncoder explizit SPARSE lassen (Performance, kein Densify)\n",
    "try:\n",
    "    cat_enc = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "except TypeError:\n",
    "    cat_enc = OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
    "\n",
    "transformers = [\n",
    "    (\"text\", TfidfVectorizer(analyzer=\"char\", ngram_range=(2,6),\n",
    "                             lowercase=True, sublinear_tf=True, min_df=1,\n",
    "                             dtype=np.float32), text_col),\n",
    "]\n",
    "if cat_cols:\n",
    "    transformers.append((\"cat\", cat_enc, cat_cols))\n",
    "if num_cols:\n",
    "    transformers.append((\"num\", num_pipe, num_cols))\n",
    "\n",
    "# Wichtig: NICHT künstlich verdichten\n",
    "pre = ColumnTransformer(transformers, remainder=\"drop\")  # kein sparse_threshold=0.0\n",
    "\n",
    "# ==== 5) MODELL A: LinearSVC ====\n",
    "svm_linear = LinearSVC(\n",
    "    C=0.5,                      # etwas höher, weil wir Numerik pushen\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=5000,\n",
    "    random_state=42\n",
    ")\n",
    "pipe_svm = Pipeline([(\"pre\", pre), (\"clf\", svm_linear)])\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = pipe_svm.predict(X_test)\n",
    "print(\"\\n=== LinearSVC (TF-IDF + Numerik*{:.1f} + country) ===\".format(NUM_BOOST))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_svm, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_svm, zero_division=0))\n",
    "\n",
    "# ==== 6) MODELL B: SGD (modified_huber) ====\n",
    "sgd = SGDClassifier(\n",
    "    loss=\"modified_huber\",\n",
    "    alpha=1e-4,                 # ggf. auf 5e-5 senken, wenn du noch mehr Numerik willst\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=5000,\n",
    "    tol=1e-3,\n",
    "    random_state=42\n",
    ")\n",
    "pipe_sgd = Pipeline([(\"pre\", pre), (\"clf\", sgd)])\n",
    "pipe_sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred_sgd = pipe_sgd.predict(X_test)\n",
    "print(\"\\n=== SGD(modified_huber) (TF-IDF + Numerik*{:.1f} + country) ===\".format(NUM_BOOST))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_sgd))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_sgd, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_sgd, zero_division=0))\n",
    "\n",
    "# ==== 7) Kurzer Wirkungs-Check: tragen die Numerik-Koeffizienten jetzt mehr? ====\n",
    "def block_norm_ratio(pipe):\n",
    "    pre = pipe.named_steps[\"pre\"]\n",
    "    clf = pipe.named_steps[\"clf\"]\n",
    "    names = pre.get_feature_names_out()\n",
    "\n",
    "    # Indexe der Numerik-Features\n",
    "    num_idx = np.array([i for i, n in enumerate(names) if n.startswith(\"num__\")])\n",
    "    if num_idx.size == 0 or not hasattr(clf, \"coef_\"):\n",
    "        return np.nan\n",
    "\n",
    "    # multi-class: L2-Norm pro Klasse mitteln\n",
    "    W = clf.coef_          # shape [K, D] (bei binary ggf. [1, D])\n",
    "    num_norm = np.mean(np.linalg.norm(W[:, num_idx], axis=1))\n",
    "    all_norm = np.mean(np.linalg.norm(W, axis=1))\n",
    "    return float(num_norm / (all_norm + 1e-12))\n",
    "\n",
    "print(\"\\n[Diagnose] Anteil der Numerik-Koeffizienten (L2-Norm) an Gesamt:\")\n",
    "print(\"LinearSVC  num/all =\", block_norm_ratio(pipe_svm))\n",
    "print(\"SGD        num/all =\", block_norm_ratio(pipe_sgd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a469bc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['asn', 'org_name', 'country', 'source', 'info_type', 'rank',\n",
       "       'asnDegree_total', 'asnDegree_customer', 'asnDegree_peer',\n",
       "       'asnDegree_provider', 'cone_numberAsns', 'cone_numberPrefixes',\n",
       "       'cone_numberAddresses', 'ASN', 'domains', 'center_lat', 'center_lon',\n",
       "       'total_weight', 'unique_points', 'country_count', 'mean_km', 'var_km2',\n",
       "       'std_km', 'iqr_km', 'p25_km', 'p50_km', 'p75_km', 'p90_km', 'p95_km',\n",
       "       'p99_km', 'min_km', 'max_km', 'pct_ips_le_100km', 'pct_ips_le_500km',\n",
       "       'pct_ips_le_1000km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peering_df_joined_with_asrank_and_domains_and_geoloc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe91f249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "org_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "70a26df4-8cbc-40af-95e6-005d031dab7a",
       "rows": [
        [
         "0",
         "gtt americas, llc"
        ],
        [
         "1",
         "akamai international b.v."
        ],
        [
         "2",
         "dalnet"
        ],
        [
         "3",
         "swisscom (schweiz) ag"
        ],
        [
         "4",
         "cox communications inc."
        ],
        [
         "5",
         "rcn"
        ],
        [
         "6",
         "charter communications inc"
        ],
        [
         "7",
         "arelion sweden ab"
        ],
        [
         "8",
         "at&t enterprises, llc"
        ],
        [
         "9",
         "verizon business"
        ],
        [
         "10",
         "gtt communications inc."
        ],
        [
         "11",
         "bbc"
        ],
        [
         "12",
         "webpass inc."
        ],
        [
         "13",
         "oracle america inc."
        ],
        [
         "14",
         "rackspace hosting"
        ],
        [
         "15",
         "korea telecom"
        ],
        [
         "16",
         "verizon business"
        ],
        [
         "17",
         "yahoo holdings inc."
        ],
        [
         "18",
         "windstream communications llc"
        ],
        [
         "19",
         "bouygues telecom sa"
        ],
        [
         "20",
         "sinister and solitary"
        ],
        [
         "21",
         "telecom italia sparkle s.p.a."
        ],
        [
         "22",
         "gtt communications inc."
        ],
        [
         "23",
         "cologix, inc"
        ],
        [
         "24",
         "jerome's furniture"
        ],
        [
         "25",
         "telstra international limited"
        ],
        [
         "26",
         "level 3 parent, llc"
        ],
        [
         "27",
         "telus communications inc."
        ],
        [
         "28",
         "rock island communications"
        ],
        [
         "29",
         "yahoo holdings inc."
        ],
        [
         "30",
         "tch network services"
        ],
        [
         "31",
         "easynet global services"
        ],
        [
         "32",
         "easynet global services"
        ],
        [
         "33",
         "enet communications limited"
        ],
        [
         "34",
         "british telecommunications plc"
        ],
        [
         "35",
         "rm education ltd"
        ],
        [
         "36",
         "plactrix technologies"
        ],
        [
         "37",
         "netcologne gesellschaft fur telekommunikation mbh"
        ],
        [
         "38",
         "zen internet ltd"
        ],
        [
         "39",
         "itility limited"
        ],
        [
         "40",
         "domainmaster ltd"
        ],
        [
         "41",
         "digital space group limited"
        ],
        [
         "42",
         "digi romania s.a."
        ],
        [
         "43",
         "gtt americas, llc"
        ],
        [
         "44",
         "orange business communications technology limited"
        ],
        [
         "45",
         "sunrise gmbh"
        ],
        [
         "46",
         "telefonica germany gmbh & co.ohg"
        ],
        [
         "47",
         "vodafone limited"
        ],
        [
         "48",
         "british telecommunications plc"
        ],
        [
         "49",
         "free sas"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 24875
       }
      },
      "text/plain": [
       "0                                        gtt americas, llc\n",
       "1                                akamai international b.v.\n",
       "2                                                   dalnet\n",
       "3                                    swisscom (schweiz) ag\n",
       "4                                  cox communications inc.\n",
       "                               ...                        \n",
       "24870    max technology & support services private limited\n",
       "24871                                                  NaN\n",
       "24872                                                  NaN\n",
       "24873                                      bjoern schleyer\n",
       "24874                                         kiwi telecom\n",
       "Name: org_name, Length: 24875, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peering_df_joined_with_asrank_and_domains_and_geoloc['org_name'].fillna('unknown').str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c3cf983",
   "metadata": {},
   "outputs": [],
   "source": [
    "peering_df_joined_with_asrank_and_domains_and_geoloc['org_name'] = peering_df_joined_with_asrank_and_domains_and_geoloc['org_name'].fillna('unknown').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13601f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer, RobustScaler, StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer, RobustScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "df = peering_df_joined_with_asrank_and_domains_and_geoloc.copy()\n",
    "X = df[['org_name', 'rank', 'asnDegree_total', 'asnDegree_customer', 'asnDegree_peer', 'asnDegree_provider', 'cone_numberAsns', 'cone_numberPrefixes',\n",
    "    'cone_numberAddresses', 'domains',  'total_weight', 'unique_points', 'country_count', 'mean_km', 'var_km2', 'std_km', 'iqr_km', 'p25_km', 'p50_km', 'p75_km', 'p90_km', 'p95_km',\n",
    "    'p99_km', 'min_km', 'max_km', 'pct_ips_le_100km', 'pct_ips_le_500km', 'pct_ips_le_1000km']]\n",
    "y = df['info_type']\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "n_classes = len(le.classes_)\n",
    "text_col = 'org_name'\n",
    "num_cols = ['rank', 'asnDegree_total', 'asnDegree_customer', 'asnDegree_peer', 'asnDegree_provider', 'cone_numberAsns', 'cone_numberPrefixes',\n",
    "    'cone_numberAddresses', 'domains',  'total_weight', 'unique_points', 'country_count', 'mean_km', 'var_km2', 'std_km', 'iqr_km', 'p25_km', 'p50_km', 'p75_km', 'p90_km', 'p95_km',\n",
    "    'p99_km', 'min_km', 'max_km', 'pct_ips_le_100km', 'pct_ips_le_500km', 'pct_ips_le_1000km']\n",
    "\n",
    "pct_cols = ['pct_ips_le_100km', 'pct_ips_le_500km', 'pct_ips_le_1000km']\n",
    "\n",
    "# Distanz-/Streumaße (km): oft stark rechtsschief\n",
    "km_cols = ['mean_km', 'var_km2', 'std_km', 'iqr_km', 'p25_km', 'p50_km', 'p75_km', 'p90_km', 'p95_km', 'p99_km',\n",
    "           'min_km', 'max_km']\n",
    "\n",
    "# Zähl-/Skalenwerte: Ränge, Degrees, Cones, Domains, Gewichte, Länder, Punkte\n",
    "count_like_cols = ['rank', 'asnDegree_total', 'asnDegree_customer', 'asnDegree_peer', 'asnDegree_provider',\n",
    "                   'cone_numberAsns', 'cone_numberPrefixes', 'cone_numberAddresses',\n",
    "                   'domains', 'total_weight', 'unique_points', 'country_count']\n",
    "\n",
    "# Falls du ASN wirklich als Zahl nutzen willst: packe ihn hier rein\n",
    "# count_like_cols += ['ASN']\n",
    "\n",
    "# --- Teil-Pipelines ---\n",
    "\n",
    "# 1) Count/Skalen: impute -> log1p -> robust scale\n",
    "count_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "    (\"log1p\", FunctionTransformer(lambda X: np.log1p(np.clip(X, a_min=0, a_max=None)), feature_names_out=\"one-to-one\")),\n",
    "    (\"scale\", RobustScaler())\n",
    "])\n",
    "\n",
    "# 2) km-Metriken: impute -> log1p -> robust scale\n",
    "km_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "    (\"log1p\", FunctionTransformer(lambda X: np.log1p(np.clip(X, a_min=0, a_max=None)), feature_names_out=\"one-to-one\")),\n",
    "    (\"scale\", RobustScaler())\n",
    "])\n",
    "\n",
    "# 3) Prozente: impute -> clip [0,1] -> standard scale\n",
    "pct_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "    (\"clip01\", FunctionTransformer(lambda X: np.clip(X, 0.0, 1.0), feature_names_out=\"one-to-one\")),\n",
    "    (\"scale\", StandardScaler())\n",
    "])\n",
    "\n",
    "# --- Text-Pipeline (deine) ---\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text_pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=(2,4),\n",
    "        min_df=1,\n",
    "        lowercase=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "text_col = \"org_name\"\n",
    "\n",
    "# --- ColumnTransformer zusammenbauen ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", text_pipe, text_col),\n",
    "        (\"num_count\", count_pipe, count_like_cols),\n",
    "        (\"num_km\", km_pipe, km_cols),\n",
    "        (\"num_pct\", pct_pipe, pct_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "clf = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", XGBClassifier(\n",
    "        tree_method=\"gpu_hist\",         # oder \"gpu_hist\" bei NVIDIA\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"mlogloss\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.25, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
