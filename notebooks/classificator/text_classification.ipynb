{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a33344",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "## Peeringdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c32292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "org_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "aka",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name_long",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "website",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "social_media",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "asn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "looking_glass",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "route_server",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "irr_as_set",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_types",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_prefixes4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "info_prefixes6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "info_traffic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_ratio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_scope",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_unicast",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "info_multicast",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "info_ipv6",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "info_never_via_route_servers",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "ix_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fac_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "notes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "netixlan_updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "netfac_updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "poc_updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "policy_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "policy_general",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "policy_locations",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "policy_ratio",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "policy_contracts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "allow_ixp_update",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "status_dashboard",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rir_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rir_status_updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "logo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "bc886bdb-2761-4714-8e32-912b57cc4c1f",
       "rows": [
        [
         "0",
         "1",
         "8897",
         "GTT Communications (AS4436)",
         "Formerly known as nLayer Communications",
         "",
         "http://www.gtt.net",
         "[{'service': 'website', 'identifier': 'http://www.gtt.net'}]",
         "4436",
         "",
         "",
         "",
         "NSP",
         "['NSP']",
         "200000.0",
         "10000.0",
         "",
         "",
         "Global",
         "True",
         "False",
         "True",
         "False",
         "0",
         "0",
         "nLayer / AS4436 has been acquired by GTT Communications / AS3257 and is no longer directly peering.  Please refer all peering related inquiries to peering [at] gtt [dot] net.",
         "2021-09-22T00:06:59Z",
         "2016-09-19T05:47:27Z",
         "2016-03-14T21:53:18Z",
         "http://www.gtt.net/peering/",
         "Restrictive",
         "Required - International",
         "True",
         "Required",
         "False",
         null,
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2022-07-27T05:33:22Z",
         "ok"
        ],
        [
         "1",
         "2",
         "14",
         "Akamai Technologies",
         "",
         "",
         "https://www.akamai.com/",
         "[{'service': 'website', 'identifier': 'https://www.akamai.com/'}]",
         "20940",
         "",
         "",
         "AS-AKAMAI",
         "Content",
         "['Content']",
         "12000.0",
         "5000.0",
         "100+Tbps",
         "Heavy Outbound",
         "Global",
         "True",
         "False",
         "True",
         "False",
         "231",
         "217",
         "",
         "2025-10-20T12:15:26Z",
         "2025-09-18T10:39:32Z",
         "2021-05-11T21:26:32Z",
         "",
         "Open",
         "Not Required",
         "False",
         "Not Required",
         "False",
         "https://www.akamaistatus.com/",
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2025-10-20T12:16:12Z",
         "ok"
        ],
        [
         "2",
         "3",
         "17",
         "DALnet IRC Network",
         "",
         "",
         "http://www.dal.net",
         "[{'service': 'website', 'identifier': 'http://www.dal.net'}]",
         "31800",
         "",
         "",
         "AS31800",
         "Non-Profit",
         "['Non-Profit']",
         "2.0",
         "0.0",
         "100-1000Mbps",
         "Heavy Inbound",
         "Global",
         "True",
         "False",
         "False",
         "False",
         "15",
         "0",
         "",
         "2025-01-09T13:41:48Z",
         null,
         "2016-03-14T21:22:01Z",
         "http://peering.dal.net",
         "Open",
         "Preferred",
         "False",
         "Not Required",
         "False",
         "",
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2025-01-09T13:42:07Z",
         "ok"
        ],
        [
         "3",
         "5",
         "9350",
         "Swisscom",
         "IP-Plus",
         "",
         "http://www.swisscom.com",
         "[{'service': 'website', 'identifier': 'http://www.swisscom.com'}]",
         "3303",
         "",
         "telnet://route-server.ip-plus.net",
         "RIPE::AS3303:AS-SWCMGLOBAL",
         "Cable/DSL/ISP",
         "['Cable/DSL/ISP']",
         "10000.0",
         "1800.0",
         "1-5Tbps",
         "Mostly Inbound",
         "Europe",
         "True",
         "False",
         "True",
         "False",
         "63",
         "32",
         "",
         "2025-10-16T06:47:17Z",
         "2025-04-10T13:25:48Z",
         "2020-01-22T04:24:08Z",
         "https://www.swisscom.ch/content/dam/swisscom/de/ws/documents/d-ott-dokumente/20230101_swisscom-peering-policy.pdf",
         "Selective",
         "Preferred",
         "True",
         "Required",
         "False",
         "",
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2025-08-12T06:33:30Z",
         "ok"
        ],
        [
         "4",
         "6",
         "23",
         "Cox Communications",
         "Cox Communications",
         "",
         "http://www.cox.com/peering",
         "[{'service': 'website', 'identifier': 'http://www.cox.com/peering'}]",
         "22773",
         "",
         "",
         "AS22773:AS-CONE",
         "Cable/DSL/ISP",
         "['Cable/DSL/ISP']",
         "10000.0",
         "3000.0",
         "100-200Gbps",
         "Mostly Inbound",
         "North America",
         "True",
         "False",
         "True",
         "False",
         "0",
         "14",
         "",
         null,
         "2022-03-24T19:56:00Z",
         "2024-03-06T01:56:24Z",
         "http://www.cox.com/peering",
         "Selective",
         "Preferred",
         "False",
         "Required",
         "False",
         "",
         "ok",
         "2024-06-26T04:47:55Z",
         null,
         "2004-07-28T00:00:00Z",
         "2022-11-28T22:55:17Z",
         "ok"
        ]
       ],
       "shape": {
        "columns": 41,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org_id</th>\n",
       "      <th>name</th>\n",
       "      <th>aka</th>\n",
       "      <th>name_long</th>\n",
       "      <th>website</th>\n",
       "      <th>social_media</th>\n",
       "      <th>asn</th>\n",
       "      <th>looking_glass</th>\n",
       "      <th>route_server</th>\n",
       "      <th>...</th>\n",
       "      <th>policy_ratio</th>\n",
       "      <th>policy_contracts</th>\n",
       "      <th>allow_ixp_update</th>\n",
       "      <th>status_dashboard</th>\n",
       "      <th>rir_status</th>\n",
       "      <th>rir_status_updated</th>\n",
       "      <th>logo</th>\n",
       "      <th>created</th>\n",
       "      <th>updated</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8897</td>\n",
       "      <td>GTT Communications (AS4436)</td>\n",
       "      <td>Formerly known as nLayer Communications</td>\n",
       "      <td></td>\n",
       "      <td>http://www.gtt.net</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>4436</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Required</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2022-07-27T05:33:22Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Akamai Technologies</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.akamai.com/</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'https:/...</td>\n",
       "      <td>20940</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Required</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.akamaistatus.com/</td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-10-20T12:16:12Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>DALnet IRC Network</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>http://www.dal.net</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>31800</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Required</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-01-09T13:42:07Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>9350</td>\n",
       "      <td>Swisscom</td>\n",
       "      <td>IP-Plus</td>\n",
       "      <td></td>\n",
       "      <td>http://www.swisscom.com</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>3303</td>\n",
       "      <td></td>\n",
       "      <td>telnet://route-server.ip-plus.net</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Required</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-08-12T06:33:30Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>Cox Communications</td>\n",
       "      <td>Cox Communications</td>\n",
       "      <td></td>\n",
       "      <td>http://www.cox.com/peering</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>22773</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Required</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2022-11-28T22:55:17Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  org_id                         name  \\\n",
       "0   1    8897  GTT Communications (AS4436)   \n",
       "1   2      14          Akamai Technologies   \n",
       "2   3      17           DALnet IRC Network   \n",
       "3   5    9350                     Swisscom   \n",
       "4   6      23           Cox Communications   \n",
       "\n",
       "                                       aka name_long  \\\n",
       "0  Formerly known as nLayer Communications             \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                  IP-Plus             \n",
       "4                       Cox Communications             \n",
       "\n",
       "                      website  \\\n",
       "0          http://www.gtt.net   \n",
       "1     https://www.akamai.com/   \n",
       "2          http://www.dal.net   \n",
       "3     http://www.swisscom.com   \n",
       "4  http://www.cox.com/peering   \n",
       "\n",
       "                                        social_media    asn looking_glass  \\\n",
       "0  [{'service': 'website', 'identifier': 'http://...   4436                 \n",
       "1  [{'service': 'website', 'identifier': 'https:/...  20940                 \n",
       "2  [{'service': 'website', 'identifier': 'http://...  31800                 \n",
       "3  [{'service': 'website', 'identifier': 'http://...   3303                 \n",
       "4  [{'service': 'website', 'identifier': 'http://...  22773                 \n",
       "\n",
       "                        route_server  ... policy_ratio policy_contracts  \\\n",
       "0                                     ...         True         Required   \n",
       "1                                     ...        False     Not Required   \n",
       "2                                     ...        False     Not Required   \n",
       "3  telnet://route-server.ip-plus.net  ...         True         Required   \n",
       "4                                     ...        False         Required   \n",
       "\n",
       "  allow_ixp_update               status_dashboard  rir_status  \\\n",
       "0            False                           None          ok   \n",
       "1            False  https://www.akamaistatus.com/          ok   \n",
       "2            False                                         ok   \n",
       "3            False                                         ok   \n",
       "4            False                                         ok   \n",
       "\n",
       "     rir_status_updated  logo               created               updated  \\\n",
       "0  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2022-07-27T05:33:22Z   \n",
       "1  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2025-10-20T12:16:12Z   \n",
       "2  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2025-01-09T13:42:07Z   \n",
       "3  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2025-08-12T06:33:30Z   \n",
       "4  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2022-11-28T22:55:17Z   \n",
       "\n",
       "   status  \n",
       "0      ok  \n",
       "1      ok  \n",
       "2      ok  \n",
       "3      ok  \n",
       "4      ok  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "filepath = Path('../../preprocessing/data/peeringdb/peeringdb_2_dump_2025_10_21.json')\n",
    "\n",
    "with filepath.open('r', encoding='utf-8') as f:\n",
    "    dump = json.load(f)\n",
    "\n",
    "# extract the net.data section and load into a DataFrame\n",
    "net_data = dump.get('net', {}).get('data')\n",
    "if net_data is None:\n",
    "    raise KeyError(\"JSON does not contain 'net' -> 'data' structure\")\n",
    "\n",
    "net_df = pd.DataFrame(net_data)\n",
    "net_df['asn'] = net_df['asn'].astype(int)\n",
    "net_df = net_df[net_df['info_type'] != '']\n",
    "\n",
    "# show a quick preview\n",
    "net_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f20d5",
   "metadata": {},
   "source": [
    "# Caida AS Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c190e0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "aut",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "changed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "org_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "org_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "afd0ebcc-ad0b-4328-afff-a94922e6d851",
       "rows": [
        [
         "0",
         "1",
         "20240618.0",
         "LPL-141-ARIN",
         "ARIN",
         "Level 3 Parent, LLC",
         "US"
        ],
        [
         "1",
         "2",
         "20231108.0",
         "UNIVER-19-Z-ARIN",
         "ARIN",
         "University of Delaware",
         "US"
        ],
        [
         "2",
         "3",
         "20100927.0",
         "MIT-2-ARIN",
         "ARIN",
         "Massachusetts Institute of Technology",
         "US"
        ],
        [
         "3",
         "4",
         "20230929.0",
         "USC-32-Z-ARIN",
         "ARIN",
         "University of Southern California",
         "US"
        ],
        [
         "4",
         "5",
         "20200723.0",
         "WGL-117-ARIN",
         "ARIN",
         "WFA Group LLC",
         "US"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aut</th>\n",
       "      <th>changed</th>\n",
       "      <th>org_id</th>\n",
       "      <th>source</th>\n",
       "      <th>org_name</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20240618.0</td>\n",
       "      <td>LPL-141-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Level 3 Parent, LLC</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20231108.0</td>\n",
       "      <td>UNIVER-19-Z-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>University of Delaware</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20100927.0</td>\n",
       "      <td>MIT-2-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20230929.0</td>\n",
       "      <td>USC-32-Z-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>University of Southern California</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20200723.0</td>\n",
       "      <td>WGL-117-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>WFA Group LLC</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aut     changed            org_id source  \\\n",
       "0    1  20240618.0      LPL-141-ARIN   ARIN   \n",
       "1    2  20231108.0  UNIVER-19-Z-ARIN   ARIN   \n",
       "2    3  20100927.0        MIT-2-ARIN   ARIN   \n",
       "3    4  20230929.0     USC-32-Z-ARIN   ARIN   \n",
       "4    5  20200723.0      WGL-117-ARIN   ARIN   \n",
       "\n",
       "                                org_name country  \n",
       "0                    Level 3 Parent, LLC      US  \n",
       "1                 University of Delaware      US  \n",
       "2  Massachusetts Institute of Technology      US  \n",
       "3      University of Southern California      US  \n",
       "4                          WFA Group LLC      US  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "with open('/workspaces/pytorch-gpu-2/preprocessing/data/caida/20251001.as-org2info.txt', 'r', newline='', encoding='utf-8') as input_file:\n",
    "    lines = input_file.readlines()   \n",
    "    # Buffers initialisieren\n",
    "    aut_lines = []\n",
    "    org_lines = []\n",
    "    mode = None\n",
    "    total_lines = len(lines)\n",
    "    aut_count = 0\n",
    "    org_count = 0 \n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"# format:aut\"):\n",
    "            mode = \"aut\"\n",
    "            continue\n",
    "        elif line.startswith(\"# format:org_id\"):\n",
    "            mode = \"org\"\n",
    "            continue\n",
    "        elif line.startswith(\"#\") or not line:\n",
    "            # Andere Kommentar- oder Leerzeilen überspringen\n",
    "            continue      \n",
    "        if mode == \"aut\":\n",
    "            aut_lines.append(line)\n",
    "            aut_count += 1\n",
    "        elif mode == \"org\":\n",
    "            org_lines.append(line)\n",
    "            org_count += 1\n",
    "    # StringIO-Objekte aus den gesammelten Zeilen bauen\n",
    "    aut_buffer = io.StringIO(\"\\n\".join(aut_lines))\n",
    "    org_buffer = io.StringIO(\"\\n\".join(org_lines))\n",
    "    # DataFrames einlesen\n",
    "    aut_df = pd.read_csv(aut_buffer, sep=\"|\",\n",
    "                        names=[\"aut\", \"changed\", \"aut_name\", \"org_id\", \"opaque_id\", \"source\"], usecols=[\"aut\", \"org_id\", \"source\", \"changed\"])\n",
    "    org_df = pd.read_csv(org_buffer, sep=\"|\",\n",
    "                        names=[\"org_id\", \"changed\", \"org_name\", \"country\", \"source\"], usecols=[\"org_id\", \"org_name\", \"country\"])\n",
    "\n",
    "    # Join the DataFrames\n",
    "    joined_df = pd.merge(aut_df, org_df, on=\"org_id\", how=\"left\")\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e5047",
   "metadata": {},
   "source": [
    "## Join both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6de8ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "asn",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "org_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "info_type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "632cc78c-89a6-4372-889d-fcd9fda6721c",
       "rows": [
        [
         "0",
         "4436",
         "GTT Americas, LLC",
         "US",
         "ARIN",
         "NSP"
        ],
        [
         "1",
         "20940",
         "Akamai International B.V.",
         "NL",
         "RIPE",
         "Content"
        ],
        [
         "2",
         "31800",
         "DALnet",
         "US",
         "ARIN",
         "Non-Profit"
        ],
        [
         "3",
         "3303",
         "Swisscom (Schweiz) AG",
         "CH",
         "RIPE",
         "Cable/DSL/ISP"
        ],
        [
         "4",
         "22773",
         "Cox Communications Inc.",
         "US",
         "ARIN",
         "Cable/DSL/ISP"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asn</th>\n",
       "      <th>org_name</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>info_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4436</td>\n",
       "      <td>GTT Americas, LLC</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>NSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20940</td>\n",
       "      <td>Akamai International B.V.</td>\n",
       "      <td>NL</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31800</td>\n",
       "      <td>DALnet</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Non-Profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3303</td>\n",
       "      <td>Swisscom (Schweiz) AG</td>\n",
       "      <td>CH</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22773</td>\n",
       "      <td>Cox Communications Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     asn                   org_name country source      info_type\n",
       "0   4436          GTT Americas, LLC      US   ARIN            NSP\n",
       "1  20940  Akamai International B.V.      NL   RIPE        Content\n",
       "2  31800                     DALnet      US   ARIN     Non-Profit\n",
       "3   3303      Swisscom (Schweiz) AG      CH   RIPE  Cable/DSL/ISP\n",
       "4  22773    Cox Communications Inc.      US   ARIN  Cable/DSL/ISP"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peering_df_joined = pd.merge(net_df, joined_df, left_on='asn', right_on='aut', how='left')\n",
    "peering_df_joined = peering_df_joined[['asn', 'org_name', 'country', 'source', 'info_type']]\n",
    "peering_df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbbfeb",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565817d",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce41b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM (calibrated) ===\n",
      "Accuracy: 0.5869140625\n",
      "Macro-F1: 0.3405334971016842\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Cable/DSL/ISP       0.62      0.93      0.74      1532\n",
      "             Content       0.43      0.34      0.38       323\n",
      "Educational/Research       0.67      0.48      0.56       189\n",
      "          Enterprise       0.43      0.13      0.20       224\n",
      "          Government       0.44      0.25      0.32        16\n",
      "                 NSP       0.42      0.17      0.24       518\n",
      "    Network Services       0.00      0.00      0.00       105\n",
      "          Non-Profit       0.65      0.30      0.41        80\n",
      "     Route Collector       0.00      0.00      0.00         4\n",
      "        Route Server       0.65      0.48      0.55        81\n",
      "\n",
      "            accuracy                           0.59      3072\n",
      "           macro avg       0.43      0.31      0.34      3072\n",
      "        weighted avg       0.53      0.59      0.53      3072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# ==== Daten ====\n",
    "df = peering_df_joined.copy()\n",
    "df[\"org_name\"] = df[\"org_name\"].fillna(\"unknown\").str.lower()\n",
    "valid = df[\"info_type\"].value_counts()\n",
    "df = df[df[\"info_type\"].isin(valid[valid >= 5].index)]  # sehr kleine Klassen raus (optional)\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df[\"org_name\"], df[\"info_type\"], test_size=0.13, random_state=42, stratify=df[\"info_type\"]\n",
    ")\n",
    "\n",
    "# Gemeinsamer Vectorizer (fit nur auf Train!)\n",
    "vec = TfidfVectorizer(analyzer=\"char\", ngram_range=(1,6),\n",
    "                      lowercase=True, min_df=1, sublinear_tf=True)\n",
    "\n",
    "# ==== 1) SVM + Kalibrierung ====\n",
    "svm = LinearSVC(C=0.35, class_weight=\"balanced\")\n",
    "svm_cal = CalibratedClassifierCV(svm, method=\"sigmoid\", cv=3)\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    (\"tfidf\", vec),\n",
    "    (\"svm_cal\", svm_cal)\n",
    "])\n",
    "\n",
    "svm_pipe.fit(X_train_text, y_train)\n",
    "y_pred_svm = svm_pipe.predict(X_test_text)\n",
    "print(\"\\n=== SVM (calibrated) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred_svm, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a706a136",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04542519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: 10 Klassen -> ['Cable/DSL/ISP', 'Content', 'Educational/Research', 'Enterprise', 'Government', 'NSP', 'Network Services', 'Non-Profit', 'Route Collector', 'Route Server']\n",
      "Device: cuda\n",
      "GPU-Name: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [0.018 0.086 0.147 0.125 1.697 0.054 0.267 0.35  6.912 0.344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5144' max='12860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5144/12860 23:15 < 34:54, 3.68 it/s, Epoch 8/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.168700</td>\n",
       "      <td>2.095237</td>\n",
       "      <td>0.420898</td>\n",
       "      <td>0.164606</td>\n",
       "      <td>0.201883</td>\n",
       "      <td>0.220511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.837300</td>\n",
       "      <td>1.827948</td>\n",
       "      <td>0.469401</td>\n",
       "      <td>0.282030</td>\n",
       "      <td>0.344930</td>\n",
       "      <td>0.338224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.755500</td>\n",
       "      <td>1.742485</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>0.305559</td>\n",
       "      <td>0.302180</td>\n",
       "      <td>0.375189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.725000</td>\n",
       "      <td>1.708697</td>\n",
       "      <td>0.527018</td>\n",
       "      <td>0.335315</td>\n",
       "      <td>0.350427</td>\n",
       "      <td>0.392946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.674400</td>\n",
       "      <td>1.727177</td>\n",
       "      <td>0.497396</td>\n",
       "      <td>0.327816</td>\n",
       "      <td>0.314828</td>\n",
       "      <td>0.383184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.472700</td>\n",
       "      <td>1.822304</td>\n",
       "      <td>0.512044</td>\n",
       "      <td>0.357610</td>\n",
       "      <td>0.354573</td>\n",
       "      <td>0.391223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.501100</td>\n",
       "      <td>1.738105</td>\n",
       "      <td>0.536784</td>\n",
       "      <td>0.354389</td>\n",
       "      <td>0.346468</td>\n",
       "      <td>0.390336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.372100</td>\n",
       "      <td>1.749050</td>\n",
       "      <td>0.466146</td>\n",
       "      <td>0.341322</td>\n",
       "      <td>0.323694</td>\n",
       "      <td>0.382001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: {'eval_loss': 1.822304368019104, 'eval_accuracy': 0.5120442708333334, 'eval_f1_macro': 0.3576104467418522, 'eval_precision': 0.35457311486282983, 'eval_recall': 0.39122302576300466, 'eval_runtime': 1.157, 'eval_samples_per_second': 2655.132, 'eval_steps_per_second': 82.973, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('xlmr_org_trainer_out/model/tokenizer_config.json',\n",
       " 'xlmr_org_trainer_out/model/special_tokens_map.json',\n",
       " 'xlmr_org_trainer_out/model/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Ersatz für den HF-Datasets-Teil (kein pyarrow/datasets nötig) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          DataCollatorWithPadding, TrainingArguments, Trainer,\n",
    "                          EarlyStoppingCallback, TextClassificationPipeline)\n",
    "\n",
    "# --------- Konfig ---------\n",
    "MODEL_NAME   = \"xlm-roberta-base\"   # multilingual, starkes Baseline-Modell\n",
    "MAX_LENGTH   = 64                   # Org-Namen sind kurz -> 64 reicht\n",
    "LR           = 1e-5\n",
    "EPOCHS       = 20\n",
    "BATCH_SIZE   = 32\n",
    "WARMUP_RATIO = 0.06\n",
    "SEED         = 42\n",
    "OUT_DIR      = \"xlmr_org_trainer_out\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "le = LabelEncoder()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df = peering_df_joined\n",
    "df[\"label_id\"] = le.fit_transform(df[\"info_type\"])\n",
    "num_labels = len(le.classes_)\n",
    "print(f\"Labels: {num_labels} Klassen ->\", list(le.classes_))\n",
    "\n",
    "df[\"label_id\"] = le.fit_transform(df[\"info_type\"])\n",
    "\n",
    "\n",
    "df.fillna('Unknown', inplace=True)\n",
    "\n",
    "# Prüfe GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU-Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Warnung: Keine GPU verfügbar, CPU wird verwendet.\")\n",
    "\n",
    "# Train/Validation Split (stratifiziert)\n",
    "train_df, eval_df = train_test_split(\n",
    "    df[[\"org_name\", \"label_id\"]],\n",
    "    test_size=0.13,\n",
    "    random_state=SEED,\n",
    "    stratify=df[\"label_id\"]\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "eval_df  = eval_df.reset_index(drop=True)\n",
    "\n",
    "# Texte & Labels aus den bereits vorbereiteten DataFrames (train_df, eval_df)\n",
    "train_texts = train_df[\"org_name\"].tolist()\n",
    "eval_texts  = eval_df[\"org_name\"].tolist()\n",
    "y_train_np  = train_df[\"label_id\"].to_numpy()\n",
    "y_eval_np   = eval_df[\"label_id\"].to_numpy()\n",
    "num_labels  = df[\"label_id\"].nunique()\n",
    "\n",
    "\n",
    "\n",
    "# Tokenisierung OHNE Padding (Padding macht später der DataCollator)\n",
    "train_enc = tok(train_texts, truncation=True, max_length=MAX_LENGTH)\n",
    "eval_enc  = tok(eval_texts,  truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "class SimpleHFLikeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.enc = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(int(self.labels[idx]))\n",
    "        return item\n",
    "\n",
    "ds_train = SimpleHFLikeDataset(train_enc, y_train_np)\n",
    "ds_eval  = SimpleHFLikeDataset(eval_enc,  y_eval_np)\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer=tok)\n",
    "\n",
    "valid_classes = sorted(df[\"info_type\"].unique())\n",
    "\n",
    "# ---- Modell + Class Weights wie gehabt ----\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    id2label={int(i): c for i, c in enumerate(valid_classes)},\n",
    "    label2id={c: int(i) for i, c in enumerate(valid_classes)}\n",
    ").to(device)\n",
    "\n",
    "# Class-Weights aus dem Trainingssplit\n",
    "class_counts = np.bincount(y_train_np, minlength=num_labels)\n",
    "weights = class_counts.sum() / np.maximum(class_counts, 1)\n",
    "weights = weights / weights.mean()\n",
    "class_weights = torch.tensor(weights, dtype=torch.float, device=device)\n",
    "print(\"Class weights:\", np.round(weights, 3))\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**{k:v for k,v in inputs.items() if k != \"labels\"})\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=OUT_DIR + \"/checkpoints\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    fp16=(device.type==\"cuda\"),\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    seed=SEED,\n",
    "    report_to=[\"none\"],\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "    return {\n",
    "        \"accuracy\":  float(accuracy_score(labels, preds)),\n",
    "        \"f1_macro\":  float(f1_score(labels, preds, average=\"macro\")),\n",
    "        \"precision\": float(precision_score(labels, preds, average=\"macro\", zero_division=0)),\n",
    "        \"recall\":    float(recall_score(labels, preds, average=\"macro\")),\n",
    "    }\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_eval,\n",
    "    tokenizer=tok,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(\"Eval:\", metrics)\n",
    "\n",
    "trainer.save_model(OUT_DIR + \"/model\")\n",
    "tok.save_pretrained(OUT_DIR + \"/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa48be66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ensemble-Gewichtssuche ===\n",
      "Bestes w (SVM-Anteil): 0.60 | Macro-F1: 0.3793 | Acc: 0.5993\n",
      "\n",
      "=== Ensemble (SVM^w + XLM-R^(1-w)) auf Eval ===\n",
      "Accuracy: 0.5992838541666666\n",
      "Macro-F1: 0.3792544149591472\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Cable/DSL/ISP       0.67      0.88      0.76      1532\n",
      "             Content       0.43      0.41      0.42       323\n",
      "Educational/Research       0.59      0.74      0.66       189\n",
      "          Enterprise       0.34      0.24      0.28       224\n",
      "          Government       0.40      0.50      0.44        16\n",
      "                 NSP       0.41      0.17      0.24       518\n",
      "    Network Services       0.00      0.00      0.00       105\n",
      "          Non-Profit       0.67      0.30      0.41        80\n",
      "     Route Collector       0.00      0.00      0.00         4\n",
      "        Route Server       0.57      0.58      0.57        81\n",
      "\n",
      "            accuracy                           0.60      3072\n",
      "           macro avg       0.41      0.38      0.38      3072\n",
      "        weighted avg       0.54      0.60      0.55      3072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ==== Ensemble aus kalibrierter SVM + XLM-R (Late Fusion) ====\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 1) Hilfsfunktionen: Probas holen und Klassenreihenfolge erzwingen\n",
    "label_names = list(valid_classes)  # <- gleiche Reihenfolge wie beim HF-Modell (id2label/label2id)\n",
    "label_index = {lbl: i for i, lbl in enumerate(label_names)}\n",
    "\n",
    "def svm_proba(texts):\n",
    "    \"\"\"Kalibrierte SVM-Probas in label_names-Reihenfolge.\"\"\"\n",
    "    # svm_pipe.classes_ enthält die Klassenreihenfolge des SVM-Teils\n",
    "    svm_labels = list(svm_pipe.named_steps[\"svm_cal\"].classes_) if hasattr(svm_pipe.named_steps[\"svm_cal\"], \"classes_\") \\\n",
    "                 else list(svm_pipe.classes_)\n",
    "    proba = svm_pipe.predict_proba(texts)  # shape: [N, n_classes_svm]\n",
    "    # Auf label_names umsortieren\n",
    "    idx_map = [svm_labels.index(lbl) for lbl in label_names]\n",
    "    proba_sorted = proba[:, idx_map]\n",
    "    return proba_sorted\n",
    "\n",
    "@torch.no_grad()\n",
    "def xlmr_proba(texts, batch_size=64, max_length=256):\n",
    "    \"\"\"Transformer-Softmax-Probas in label_names-Reihenfolge (id2label stimmt auf valid_classes).\"\"\"\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tok(batch, truncation=True, max_length=max_length, padding=True, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(model.device) for k, v in enc.items()}\n",
    "        logits = model(**enc).logits  # [B, num_labels]\n",
    "        probs = torch.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        all_probs.append(probs)\n",
    "    return np.vstack(all_probs)  # [N, num_labels] schon in label_names-Reihenfolge\n",
    "\n",
    "# 2) Probas auf deinem (Ensemble-)Validierungs/Testsplit erzeugen\n",
    "X_eval = eval_df[\"org_name\"].tolist()\n",
    "y_eval = y_eval_np  # ints passend zur Reihenfolge in label_names\n",
    "\n",
    "P_svm  = svm_proba(X_eval)              # [N, C]\n",
    "P_xlmr = xlmr_proba(X_eval, max_length=MAX_LENGTH)  # [N, C]\n",
    "\n",
    "# 3) Gewicht per einfacher Grid-Search finden (0..1)\n",
    "grid = np.linspace(0.0, 1.0, 21)  # 0.00, 0.05, ..., 1.00\n",
    "best = {\"w\": None, \"f1\": -1.0, \"acc\": 0.0}\n",
    "\n",
    "for w in grid:\n",
    "    P_ens = w * P_svm + (1.0 - w) * P_xlmr\n",
    "    y_hat = P_ens.argmax(axis=1)\n",
    "    f1 = f1_score(y_eval, y_hat, average=\"macro\")\n",
    "    acc = accuracy_score(y_eval, y_hat)\n",
    "    if f1 > best[\"f1\"] or (f1 == best[\"f1\"] and acc > best[\"acc\"]):\n",
    "        best.update({\"w\": float(w), \"f1\": float(f1), \"acc\": float(acc)})\n",
    "\n",
    "print(f\"\\n=== Ensemble-Gewichtssuche ===\")\n",
    "print(f\"Bestes w (SVM-Anteil): {best['w']:.2f} | Macro-F1: {best['f1']:.4f} | Acc: {best['acc']:.4f}\")\n",
    "\n",
    "# 4) Finale Ensemble-Vorhersage + Report\n",
    "w = best[\"w\"]\n",
    "P_ens = w * P_svm + (1.0 - w) * P_xlmr\n",
    "y_pred = P_ens.argmax(axis=1)\n",
    "\n",
    "print(\"\\n=== Ensemble (SVM^w + XLM-R^(1-w)) auf Eval ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_eval, y_pred))\n",
    "print(\"Macro-F1:\", f1_score(y_eval, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_eval, y_pred, target_names=label_names))\n",
    "\n",
    "# 5) Praktische Inferenzfunktion fürs spätere Nutzen\n",
    "def ensemble_predict(texts, return_proba=False, batch_size=64):\n",
    "    Ps = svm_proba(texts)\n",
    "    Pt = xlmr_proba(texts, batch_size=batch_size, max_length=MAX_LENGTH)\n",
    "    P = w * Ps + (1.0 - w) * Pt\n",
    "    preds = P.argmax(axis=1)\n",
    "    if return_proba:\n",
    "        return preds, P\n",
    "    return preds\n",
    "\n",
    "# Beispiel:\n",
    "# preds, proba = ensemble_predict([\"google llc\", \"university of oxford\"], return_proba=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5cfdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Temperature Scaling ===\n",
      "Beste Temperatur T: 1.00\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'safe_logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m P_xlmr_cal \u001b[38;5;241m=\u001b[39m softmax(Z \u001b[38;5;241m/\u001b[39m T)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Danach z.B. mit Logit-Blending (s. oben) erneut w suchen:\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m Ls \u001b[38;5;241m=\u001b[39m \u001b[43msafe_logits\u001b[49m(P_svm); Lt \u001b[38;5;241m=\u001b[39m safe_logits(P_xlmr_cal)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# ... identischer Grid-Search-Code wie oben ...\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'safe_logits' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def xlmr_logits(texts, batch_size=64, max_length=256):\n",
    "    model.eval()\n",
    "    outs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tok(batch, truncation=True, max_length=max_length, padding=True, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(model.device) for k, v in enc.items()}\n",
    "        outs.append(model(**enc).logits.detach().cpu().numpy())\n",
    "    return np.vstack(outs)\n",
    "\n",
    "# 1) Roh-Logits holen\n",
    "Z = xlmr_logits(eval_df[\"org_name\"].tolist(), max_length=MAX_LENGTH)  # [N, C]\n",
    "\n",
    "# 2) Optimale Temperatur per NLL auf Eval suchen\n",
    "def softmax(z): \n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    ez = np.exp(z)\n",
    "    return ez / ez.sum(axis=1, keepdims=True)\n",
    "\n",
    "def best_temperature(logits, y, grid=np.linspace(0.5, 3.0, 26)):\n",
    "    best_T, best_nll = 1.0, 1e9\n",
    "    for T in grid:\n",
    "        P = softmax(logits / T)\n",
    "        nll = log_loss(y, P, labels=list(range(P.shape[1])))\n",
    "        if nll < best_nll:\n",
    "            best_T, best_nll = float(T), float(nll)\n",
    "    return best_T\n",
    "\n",
    "T = best_temperature(Z, y_eval)\n",
    "print(f\"\\n=== Temperature Scaling ===\\nBeste Temperatur T: {T:.2f}\")\n",
    "\n",
    "# 3) Kalibrierte XLM-R-Probas neu berechnen und erneut ensemblen\n",
    "P_xlmr_cal = softmax(Z / T)\n",
    "# Danach z.B. mit Logit-Blending (s. oben) erneut w suchen:\n",
    "Ls = safe_logits(P_svm); Lt = safe_logits(P_xlmr_cal)\n",
    "# ... identischer Grid-Search-Code wie oben ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3094bc27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, f1_score, accuracy_score\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ==== Beispiel-Daten ====\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# df = peering_df_joined.copy()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# df[\"org_name\"], df[\"country\"], df[\"asn\"], df[\"ix_count\"], df[\"info_type\"]\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     16\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m??\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mix_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mix_count\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "# ==== Beispiel-Daten ====\n",
    "df = peering_df_joined.copy()\n",
    "# df[\"org_name\"], df[\"country\"], df[\"asn\"], df[\"ix_count\"], df[\"info_type\"]\n",
    "\n",
    "df[\"org_name\"] = df[\"org_name\"].fillna(\"unknown\").str.lower()\n",
    "df[\"country\"] = df[\"country\"].fillna(\"??\")\n",
    "df[\"ix_count\"] = df[\"ix_count\"].fillna(0)\n",
    "\n",
    "# ==== Hilfsfunktion für Regex-Features aus dem Namen ====\n",
    "def regex_features(X):\n",
    "    X = X[\"org_name\"].astype(str).str.lower()\n",
    "    return pd.DataFrame({\n",
    "        \"has_isp\": X.str.contains(r\"isp|telecom|broadband|internet\").astype(int),\n",
    "        \"has_univ\": X.str.contains(r\"univ|college|schule|academy\").astype(int),\n",
    "        \"has_gov\": X.str.contains(r\"gov|ministerium|city|state|municipal\").astype(int),\n",
    "        \"has_ix\": X.str.contains(r\"\\bix\\b|exchange|route\").astype(int),\n",
    "        \"has_asn\": X.str.contains(r\"as\\d+\").astype(int),\n",
    "    })\n",
    "\n",
    "# ==== Spalten definieren ====\n",
    "text_col = \"org_name\"\n",
    "regex_col = [\"org_name\"]\n",
    "\n",
    "# ==== ColumnTransformer aufbauen ====\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"tfidf\", TfidfVectorizer(analyzer=\"char\", ngram_range=(2,6), sublinear_tf=True), text_col),\n",
    "    (\"regex\", FunctionTransformer(regex_features), regex_col)\n",
    "])\n",
    "\n",
    "# ==== Modell ====\n",
    "svm = LinearSVC(C=0.35, class_weight=\"balanced\")\n",
    "svm_cal = CalibratedClassifierCV(svm, method=\"sigmoid\", cv=3)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"features\", preprocessor),\n",
    "    (\"clf\", svm_cal)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
