{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0b9afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org_id</th>\n",
       "      <th>name</th>\n",
       "      <th>aka</th>\n",
       "      <th>name_long</th>\n",
       "      <th>website</th>\n",
       "      <th>social_media</th>\n",
       "      <th>asn</th>\n",
       "      <th>looking_glass</th>\n",
       "      <th>route_server</th>\n",
       "      <th>...</th>\n",
       "      <th>policy_ratio</th>\n",
       "      <th>policy_contracts</th>\n",
       "      <th>allow_ixp_update</th>\n",
       "      <th>status_dashboard</th>\n",
       "      <th>rir_status</th>\n",
       "      <th>rir_status_updated</th>\n",
       "      <th>logo</th>\n",
       "      <th>created</th>\n",
       "      <th>updated</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8897</td>\n",
       "      <td>GTT Communications (AS4436)</td>\n",
       "      <td>Formerly known as nLayer Communications</td>\n",
       "      <td></td>\n",
       "      <td>http://www.gtt.net</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>4436</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Required</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2022-07-27T05:33:22Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Akamai Technologies</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.akamai.com/</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'https:/...</td>\n",
       "      <td>20940</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Required</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.akamaistatus.com/</td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-10-20T12:16:12Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>DALnet IRC Network</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>http://www.dal.net</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>31800</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Required</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-01-09T13:42:07Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>9350</td>\n",
       "      <td>Swisscom</td>\n",
       "      <td>IP-Plus</td>\n",
       "      <td></td>\n",
       "      <td>http://www.swisscom.com</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>3303</td>\n",
       "      <td></td>\n",
       "      <td>telnet://route-server.ip-plus.net</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Required</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-08-12T06:33:30Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>Cox Communications</td>\n",
       "      <td>Cox Communications</td>\n",
       "      <td></td>\n",
       "      <td>http://www.cox.com/peering</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>22773</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Required</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2022-11-28T22:55:17Z</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  org_id                         name  \\\n",
       "0   1    8897  GTT Communications (AS4436)   \n",
       "1   2      14          Akamai Technologies   \n",
       "2   3      17           DALnet IRC Network   \n",
       "3   5    9350                     Swisscom   \n",
       "4   6      23           Cox Communications   \n",
       "\n",
       "                                       aka name_long  \\\n",
       "0  Formerly known as nLayer Communications             \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                  IP-Plus             \n",
       "4                       Cox Communications             \n",
       "\n",
       "                      website  \\\n",
       "0          http://www.gtt.net   \n",
       "1     https://www.akamai.com/   \n",
       "2          http://www.dal.net   \n",
       "3     http://www.swisscom.com   \n",
       "4  http://www.cox.com/peering   \n",
       "\n",
       "                                        social_media    asn looking_glass  \\\n",
       "0  [{'service': 'website', 'identifier': 'http://...   4436                 \n",
       "1  [{'service': 'website', 'identifier': 'https:/...  20940                 \n",
       "2  [{'service': 'website', 'identifier': 'http://...  31800                 \n",
       "3  [{'service': 'website', 'identifier': 'http://...   3303                 \n",
       "4  [{'service': 'website', 'identifier': 'http://...  22773                 \n",
       "\n",
       "                        route_server  ... policy_ratio policy_contracts  \\\n",
       "0                                     ...         True         Required   \n",
       "1                                     ...        False     Not Required   \n",
       "2                                     ...        False     Not Required   \n",
       "3  telnet://route-server.ip-plus.net  ...         True         Required   \n",
       "4                                     ...        False         Required   \n",
       "\n",
       "  allow_ixp_update               status_dashboard  rir_status  \\\n",
       "0            False                           None          ok   \n",
       "1            False  https://www.akamaistatus.com/          ok   \n",
       "2            False                                         ok   \n",
       "3            False                                         ok   \n",
       "4            False                                         ok   \n",
       "\n",
       "     rir_status_updated  logo               created               updated  \\\n",
       "0  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2022-07-27T05:33:22Z   \n",
       "1  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2025-10-20T12:16:12Z   \n",
       "2  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2025-01-09T13:42:07Z   \n",
       "3  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2025-08-12T06:33:30Z   \n",
       "4  2024-06-26T04:47:55Z  None  2004-07-28T00:00:00Z  2022-11-28T22:55:17Z   \n",
       "\n",
       "   status  \n",
       "0      ok  \n",
       "1      ok  \n",
       "2      ok  \n",
       "3      ok  \n",
       "4      ok  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# locate a likely PeeringDB dump JSON in the workspace\n",
    "candidates = list(Path('.').glob('*peeringdb*dump*.json')) + list(Path('.').glob('peeringdb*.json'))\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(\"PeeringDB dump JSON not found. Place a file like 'peeringdb_dump.json' in the working directory.\")\n",
    "filepath = candidates[0]\n",
    "\n",
    "with filepath.open('r', encoding='utf-8') as f:\n",
    "    dump = json.load(f)\n",
    "\n",
    "# extract the net.data section and load into a DataFrame\n",
    "net_data = dump.get('net', {}).get('data')\n",
    "if net_data is None:\n",
    "    raise KeyError(\"JSON does not contain 'net' -> 'data' structure\")\n",
    "\n",
    "net_df = pd.DataFrame(net_data)\n",
    "net_df['asn'] = net_df['asn'].astype(int)\n",
    "net_df = net_df[net_df['info_type'] != '']\n",
    "\n",
    "# show a quick preview\n",
    "net_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd351f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>org_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name_long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>social_media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>asn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>looking_glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>route_server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>irr_as_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>info_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>info_types</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>info_prefixes4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>info_prefixes6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>info_traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>info_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>info_scope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>info_unicast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>info_multicast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>info_ipv6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>info_never_via_route_servers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ix_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fac_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>netixlan_updated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>netfac_updated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>poc_updated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>policy_url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>policy_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>policy_locations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>policy_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>policy_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>allow_ixp_update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>status_dashboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>rir_status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>rir_status_updated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>logo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>updated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>status</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          column\n",
       "0                             id\n",
       "1                         org_id\n",
       "2                           name\n",
       "3                            aka\n",
       "4                      name_long\n",
       "5                        website\n",
       "6                   social_media\n",
       "7                            asn\n",
       "8                  looking_glass\n",
       "9                   route_server\n",
       "10                    irr_as_set\n",
       "11                     info_type\n",
       "12                    info_types\n",
       "13                info_prefixes4\n",
       "14                info_prefixes6\n",
       "15                  info_traffic\n",
       "16                    info_ratio\n",
       "17                    info_scope\n",
       "18                  info_unicast\n",
       "19                info_multicast\n",
       "20                     info_ipv6\n",
       "21  info_never_via_route_servers\n",
       "22                      ix_count\n",
       "23                     fac_count\n",
       "24                         notes\n",
       "25              netixlan_updated\n",
       "26                netfac_updated\n",
       "27                   poc_updated\n",
       "28                    policy_url\n",
       "29                policy_general\n",
       "30              policy_locations\n",
       "31                  policy_ratio\n",
       "32              policy_contracts\n",
       "33              allow_ixp_update\n",
       "34              status_dashboard\n",
       "35                    rir_status\n",
       "36            rir_status_updated\n",
       "37                          logo\n",
       "38                       created\n",
       "39                       updated\n",
       "40                        status"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all columns in net_df (net_df is defined in a previous cell)\n",
    "print(f\"{len(net_df.columns)} columns:\")\n",
    "pd.DataFrame(net_df.columns, columns=[\"column\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66bf444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_stats(dataframe, column_name):\n",
    "    numeric_data = pd.to_datetime(dataframe[column_name]).astype(int) / 10**9\n",
    "    stats = {\n",
    "        'min': pd.to_datetime(numeric_data.min(), unit='s'),\n",
    "        'max': pd.to_datetime(numeric_data.max(), unit='s'),\n",
    "        'median': pd.to_datetime(numeric_data.median(), unit='s'),\n",
    "        'mean': pd.to_datetime(numeric_data.mean(), unit='s'),\n",
    "        '10-percentile': pd.to_datetime(numeric_data.quantile(0.1), unit='s'),\n",
    "        '20-percentile': pd.to_datetime(numeric_data.quantile(0.2), unit='s'),\n",
    "        '30-percentile': pd.to_datetime(numeric_data.quantile(0.3), unit='s'),\n",
    "        '40-percentile': pd.to_datetime(numeric_data.quantile(0.4), unit='s'),\n",
    "        '50-percentile': pd.to_datetime(numeric_data.quantile(0.5), unit='s'),\n",
    "        '60-percentile': pd.to_datetime(numeric_data.quantile(0.6), unit='s'),\n",
    "        '70-percentile': pd.to_datetime(numeric_data.quantile(0.7), unit='s'),\n",
    "        '80-percentile': pd.to_datetime(numeric_data.quantile(0.8), unit='s'),\n",
    "        '90-percentile': pd.to_datetime(numeric_data.quantile(0.9), unit='s'),\n",
    "    }\n",
    "    for key, value in stats.items():\n",
    "        stats[key] = pd.to_datetime(value, unit='s')\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f13551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': Timestamp('2022-07-27 05:33:15'),\n",
       " 'max': Timestamp('2025-10-22 03:59:18'),\n",
       " 'median': Timestamp('2024-03-23 06:38:05.500000'),\n",
       " 'mean': Timestamp('2024-01-10 22:15:54.764705792'),\n",
       " '10-percentile': Timestamp('2022-07-27 05:34:16'),\n",
       " '20-percentile': Timestamp('2022-07-27 05:35:47'),\n",
       " '30-percentile': Timestamp('2022-07-27 05:37:01.700000'),\n",
       " '40-percentile': Timestamp('2023-04-07 12:59:21'),\n",
       " '50-percentile': Timestamp('2024-03-23 06:38:05.500000'),\n",
       " '60-percentile': Timestamp('2024-09-18 05:03:41.600000'),\n",
       " '70-percentile': Timestamp('2025-02-10 14:26:01.600000'),\n",
       " '80-percentile': Timestamp('2025-05-26 12:18:01.400000'),\n",
       " '90-percentile': Timestamp('2025-08-22 10:22:03.400000')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_stats(net_df, 'updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182c7195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': Timestamp('2004-07-28 00:00:00'),\n",
       " 'max': Timestamp('2025-10-21 14:40:30'),\n",
       " 'median': Timestamp('2019-06-05 06:46:23.500000'),\n",
       " 'mean': Timestamp('2018-10-16 00:34:18.902496768'),\n",
       " '10-percentile': Timestamp('2011-10-27 13:48:24.900000'),\n",
       " '20-percentile': Timestamp('2015-09-17 13:19:00.200000'),\n",
       " '30-percentile': Timestamp('2017-02-03 04:00:07.300000'),\n",
       " '40-percentile': Timestamp('2018-04-03 09:04:01.200000'),\n",
       " '50-percentile': Timestamp('2019-06-05 06:46:23.500000'),\n",
       " '60-percentile': Timestamp('2020-07-04 02:40:40.200000'),\n",
       " '70-percentile': Timestamp('2021-08-19 12:40:45.400000'),\n",
       " '80-percentile': Timestamp('2022-12-20 15:34:28.400000'),\n",
       " '90-percentile': Timestamp('2024-05-08 20:59:50.900000')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_stats(net_df, 'created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74efd496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': NaT,\n",
       " 'max': Timestamp('2025-10-21 22:55:08'),\n",
       " 'median': Timestamp('2024-06-26 04:47:55'),\n",
       " 'mean': Timestamp('2024-07-16 02:43:55.537119744'),\n",
       " '10-percentile': Timestamp('2024-06-26 04:47:55'),\n",
       " '20-percentile': Timestamp('2024-06-26 04:47:55'),\n",
       " '30-percentile': Timestamp('2024-06-26 04:47:55'),\n",
       " '40-percentile': Timestamp('2024-06-26 04:47:55'),\n",
       " '50-percentile': Timestamp('2024-06-26 04:47:55'),\n",
       " '60-percentile': Timestamp('2024-06-26 04:47:55'),\n",
       " '70-percentile': Timestamp('2024-06-26 04:47:55'),\n",
       " '80-percentile': Timestamp('2024-06-26 04:47:55'),\n",
       " '90-percentile': Timestamp('2024-07-22 12:47:41')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_stats(net_df, 'rir_status_updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df8347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1175/643203660.py:8: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nro_df = pd.read_csv(filepath, sep='|', header=None, names=['rir', 'country', 'type', 'asn', 'size', 'ignore1', 'status', 'ignore2', 'ignore3'], on_bad_lines='skip')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_config/config.py:620\u001b[0m, in \u001b[0;36m_get_deprecated_option\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 620\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43m_deprecated_options\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mode.copy_on_write'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m count \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(count):\n\u001b[0;32m---> 19\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     new_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(start_asn \u001b[38;5;241m+\u001b[39m i)\n\u001b[1;32m     21\u001b[0m     expanded_rows\u001b[38;5;241m.\u001b[39mappend(new_row)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py:6368\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6258\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   6259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   6260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6261\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[1;32m   6262\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6366\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   6367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6368\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   6370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:651\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m--> 651\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m new_refs: \u001b[38;5;28mlist\u001b[39m[weakref\u001b[38;5;241m.\u001b[39mref \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:362\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_failures:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine(result_blocks)\n\u001b[0;32m--> 362\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:1929\u001b[0m, in \u001b[0;36mSingleBlockManager.from_blocks\u001b[0;34m(cls, blocks, axes, refs, parent)\u001b[0m\n\u001b[1;32m   1927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1928\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(refs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1929\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:1912\u001b[0m, in \u001b[0;36mSingleBlockManager.__init__\u001b[0;34m(self, block, axis, refs, parent, verify_integrity, fastpath)\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m (block,)\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;241m=\u001b[39m refs\n\u001b[0;32m-> 1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m=\u001b[39m parent \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_using_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py:2428\u001b[0m, in \u001b[0;36m_using_copy_on_write\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_using_copy_on_write\u001b[39m():\n\u001b[0;32m-> 2428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode.copy_on_write\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_config/config.py:263\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_config/config.py:135\u001b[0m, in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_option\u001b[39m(pat: \u001b[38;5;28mstr\u001b[39m, silent: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 135\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     root, k \u001b[38;5;241m=\u001b[39m _get_root(key)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_config/config.py:127\u001b[0m, in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    124\u001b[0m key \u001b[38;5;241m=\u001b[39m keys[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[0;32m--> 127\u001b[0m     \u001b[43m_warn_if_deprecated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m key \u001b[38;5;241m=\u001b[39m _translate_key(key)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_config/config.py:658\u001b[0m, in \u001b[0;36m_warn_if_deprecated\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_warn_if_deprecated\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    651\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;124;03m    Checks if `key` is a deprecated option and if so, prints a warning.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03m    bool - True if `key` is deprecated, False otherwise.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43m_get_deprecated_option\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m d:\n\u001b[1;32m    660\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m d\u001b[38;5;241m.\u001b[39mmsg:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_config/config.py:620\u001b[0m, in \u001b[0;36m_get_deprecated_option\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03mRetrieves the metadata for a deprecated option, if `key` is deprecated.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03mDeprecatedOption (namedtuple) if key is deprecated, None otherwise\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 620\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43m_deprecated_options\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "filepath = '../nro-delegated-stats/nro-delegated-stats'\n",
    "\n",
    "# load the delegated stats into a DataFrame\n",
    "# assuming it's a pipe-separated file with no header\n",
    "nro_df = pd.read_csv(filepath, sep='|', header=None, names=['rir', 'country', 'type', 'asn', 'size', 'ignore1', 'status', 'ignore2', 'ignore3'], on_bad_lines='skip')\n",
    "nro_df = nro_df[nro_df['type'] == 'asn']\n",
    "nro_df.dropna(inplace=True)\n",
    "nro_df = nro_df[nro_df['country'] != 'ZZ']\n",
    "\n",
    "# expand nro_df to include individual ASNs based on size\n",
    "expanded_rows = []\n",
    "for _, row in nro_df.iterrows():\n",
    "    start_asn = int(row['asn'])\n",
    "    count = row['size']\n",
    "    for i in range(count):\n",
    "        new_row = row.copy()\n",
    "        new_row['asn'] = str(start_asn + i)\n",
    "        expanded_rows.append(new_row)\n",
    "nro_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# show a quick preview\n",
    "nro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f86a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ripencc    38960\n",
       "arin       33517\n",
       "apnic      30532\n",
       "lacnic     13912\n",
       "afrinic     2603\n",
       "Name: rir, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nro_df['rir'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39007594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rir</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>asn</th>\n",
       "      <th>size</th>\n",
       "      <th>ignore1</th>\n",
       "      <th>status</th>\n",
       "      <th>ignore2</th>\n",
       "      <th>ignore3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>ripencc</td>\n",
       "      <td>DE</td>\n",
       "      <td>asn</td>\n",
       "      <td>3320</td>\n",
       "      <td>1</td>\n",
       "      <td>19950223</td>\n",
       "      <td>assigned</td>\n",
       "      <td>4227b4f5-07d9-4852-b1d5-26559261d043</td>\n",
       "      <td>e-stats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rir country type   asn  size   ignore1    status  \\\n",
       "2669  ripencc      DE  asn  3320     1  19950223  assigned   \n",
       "\n",
       "                                   ignore2  ignore3  \n",
       "2669  4227b4f5-07d9-4852-b1d5-26559261d043  e-stats  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nro_df[nro_df['asn'] == '3320']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f08f1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>org_id</th>\n",
       "      <th>name</th>\n",
       "      <th>aka</th>\n",
       "      <th>name_long</th>\n",
       "      <th>website</th>\n",
       "      <th>social_media</th>\n",
       "      <th>asn</th>\n",
       "      <th>looking_glass</th>\n",
       "      <th>route_server</th>\n",
       "      <th>...</th>\n",
       "      <th>allow_ixp_update</th>\n",
       "      <th>status_dashboard</th>\n",
       "      <th>rir_status</th>\n",
       "      <th>rir_status_updated</th>\n",
       "      <th>logo</th>\n",
       "      <th>created</th>\n",
       "      <th>updated</th>\n",
       "      <th>status</th>\n",
       "      <th>rir</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8897</td>\n",
       "      <td>GTT Communications (AS4436)</td>\n",
       "      <td>Formerly known as nLayer Communications</td>\n",
       "      <td></td>\n",
       "      <td>http://www.gtt.net</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>4436</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2022-07-27T05:33:22Z</td>\n",
       "      <td>ok</td>\n",
       "      <td>arin</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Akamai Technologies</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.akamai.com/</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'https:/...</td>\n",
       "      <td>20940</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.akamaistatus.com/</td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-10-20T12:16:12Z</td>\n",
       "      <td>ok</td>\n",
       "      <td>ripencc</td>\n",
       "      <td>NL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>DALnet IRC Network</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>http://www.dal.net</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>31800</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-01-09T13:42:07Z</td>\n",
       "      <td>ok</td>\n",
       "      <td>arin</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>9350</td>\n",
       "      <td>Swisscom</td>\n",
       "      <td>IP-Plus</td>\n",
       "      <td></td>\n",
       "      <td>http://www.swisscom.com</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>3303</td>\n",
       "      <td></td>\n",
       "      <td>telnet://route-server.ip-plus.net</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2025-08-12T06:33:30Z</td>\n",
       "      <td>ok</td>\n",
       "      <td>ripencc</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>Cox Communications</td>\n",
       "      <td>Cox Communications</td>\n",
       "      <td></td>\n",
       "      <td>http://www.cox.com/peering</td>\n",
       "      <td>[{'service': 'website', 'identifier': 'http://...</td>\n",
       "      <td>22773</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>ok</td>\n",
       "      <td>2024-06-26T04:47:55Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2004-07-28T00:00:00Z</td>\n",
       "      <td>2022-11-28T22:55:17Z</td>\n",
       "      <td>ok</td>\n",
       "      <td>arin</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  org_id                         name  \\\n",
       "0   1    8897  GTT Communications (AS4436)   \n",
       "1   2      14          Akamai Technologies   \n",
       "2   3      17           DALnet IRC Network   \n",
       "3   5    9350                     Swisscom   \n",
       "4   6      23           Cox Communications   \n",
       "\n",
       "                                       aka name_long  \\\n",
       "0  Formerly known as nLayer Communications             \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                  IP-Plus             \n",
       "4                       Cox Communications             \n",
       "\n",
       "                      website  \\\n",
       "0          http://www.gtt.net   \n",
       "1     https://www.akamai.com/   \n",
       "2          http://www.dal.net   \n",
       "3     http://www.swisscom.com   \n",
       "4  http://www.cox.com/peering   \n",
       "\n",
       "                                        social_media    asn looking_glass  \\\n",
       "0  [{'service': 'website', 'identifier': 'http://...   4436                 \n",
       "1  [{'service': 'website', 'identifier': 'https:/...  20940                 \n",
       "2  [{'service': 'website', 'identifier': 'http://...  31800                 \n",
       "3  [{'service': 'website', 'identifier': 'http://...   3303                 \n",
       "4  [{'service': 'website', 'identifier': 'http://...  22773                 \n",
       "\n",
       "                        route_server  ... allow_ixp_update  \\\n",
       "0                                     ...            False   \n",
       "1                                     ...            False   \n",
       "2                                     ...            False   \n",
       "3  telnet://route-server.ip-plus.net  ...            False   \n",
       "4                                     ...            False   \n",
       "\n",
       "                status_dashboard rir_status    rir_status_updated  logo  \\\n",
       "0                           None         ok  2024-06-26T04:47:55Z  None   \n",
       "1  https://www.akamaistatus.com/         ok  2024-06-26T04:47:55Z  None   \n",
       "2                                        ok  2024-06-26T04:47:55Z  None   \n",
       "3                                        ok  2024-06-26T04:47:55Z  None   \n",
       "4                                        ok  2024-06-26T04:47:55Z  None   \n",
       "\n",
       "                created               updated status      rir  country  \n",
       "0  2004-07-28T00:00:00Z  2022-07-27T05:33:22Z     ok     arin       US  \n",
       "1  2004-07-28T00:00:00Z  2025-10-20T12:16:12Z     ok  ripencc       NL  \n",
       "2  2004-07-28T00:00:00Z  2025-01-09T13:42:07Z     ok     arin       US  \n",
       "3  2004-07-28T00:00:00Z  2025-08-12T06:33:30Z     ok  ripencc       CH  \n",
       "4  2004-07-28T00:00:00Z  2022-11-28T22:55:17Z     ok     arin       US  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge net_df with nro_df on 'asn' to add RIR and country information\n",
    "net_df['asn'] = net_df['asn'].astype(str)\n",
    "merged_df = net_df.merge(nro_df[['asn', 'rir', 'country']], on='asn', how='left')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3f7836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ripencc    8396\n",
       "lacnic     5292\n",
       "apnic      5165\n",
       "arin       3758\n",
       "afrinic     928\n",
       "Name: rir, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['rir'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2db449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "with open('/workspaces/pytorch-gpu-2/preprocessing/data/caida/20251001.as-org2info.txt', 'r', newline='', encoding='utf-8') as input_file:\n",
    "    lines = input_file.readlines()   \n",
    "    # Buffers initialisieren\n",
    "    aut_lines = []\n",
    "    org_lines = []\n",
    "    mode = None\n",
    "    total_lines = len(lines)\n",
    "    aut_count = 0\n",
    "    org_count = 0 \n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"# format:aut\"):\n",
    "            mode = \"aut\"\n",
    "            continue\n",
    "        elif line.startswith(\"# format:org_id\"):\n",
    "            mode = \"org\"\n",
    "            continue\n",
    "        elif line.startswith(\"#\") or not line:\n",
    "            # Andere Kommentar- oder Leerzeilen Ã¼berspringen\n",
    "            continue      \n",
    "        if mode == \"aut\":\n",
    "            aut_lines.append(line)\n",
    "            aut_count += 1\n",
    "        elif mode == \"org\":\n",
    "            org_lines.append(line)\n",
    "            org_count += 1\n",
    "    # StringIO-Objekte aus den gesammelten Zeilen bauen\n",
    "    aut_buffer = io.StringIO(\"\\n\".join(aut_lines))\n",
    "    org_buffer = io.StringIO(\"\\n\".join(org_lines))\n",
    "    # DataFrames einlesen\n",
    "    aut_df = pd.read_csv(aut_buffer, sep=\"|\",\n",
    "                        names=[\"aut\", \"changed\", \"aut_name\", \"org_id\", \"opaque_id\", \"source\"], usecols=[\"aut\", \"org_id\", \"source\", \"changed\"])\n",
    "    org_df = pd.read_csv(org_buffer, sep=\"|\",\n",
    "                        names=[\"org_id\", \"changed\", \"org_name\", \"country\", \"source\"], usecols=[\"org_id\", \"org_name\", \"country\"])\n",
    "\n",
    "    # Join the DataFrames\n",
    "    joined_df = pd.merge(aut_df, org_df, on=\"org_id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26a2b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aut</th>\n",
       "      <th>changed</th>\n",
       "      <th>org_id</th>\n",
       "      <th>source</th>\n",
       "      <th>org_name</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20240618.0</td>\n",
       "      <td>LPL-141-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Level 3 Parent, LLC</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20231108.0</td>\n",
       "      <td>UNIVER-19-Z-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>University of Delaware</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20100927.0</td>\n",
       "      <td>MIT-2-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20230929.0</td>\n",
       "      <td>USC-32-Z-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>University of Southern California</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20200723.0</td>\n",
       "      <td>WGL-117-ARIN</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>WFA Group LLC</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aut     changed            org_id source  \\\n",
       "0    1  20240618.0      LPL-141-ARIN   ARIN   \n",
       "1    2  20231108.0  UNIVER-19-Z-ARIN   ARIN   \n",
       "2    3  20100927.0        MIT-2-ARIN   ARIN   \n",
       "3    4  20230929.0     USC-32-Z-ARIN   ARIN   \n",
       "4    5  20200723.0      WGL-117-ARIN   ARIN   \n",
       "\n",
       "                                org_name country  \n",
       "0                    Level 3 Parent, LLC      US  \n",
       "1                 University of Delaware      US  \n",
       "2  Massachusetts Institute of Technology      US  \n",
       "3      University of Southern California      US  \n",
       "4                          WFA Group LLC      US  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e228d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asn</th>\n",
       "      <th>org_name</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>info_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4436</td>\n",
       "      <td>GTT Americas, LLC</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>NSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20940</td>\n",
       "      <td>Akamai International B.V.</td>\n",
       "      <td>NL</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31800</td>\n",
       "      <td>DALnet</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Non-Profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3303</td>\n",
       "      <td>Swisscom (Schweiz) AG</td>\n",
       "      <td>CH</td>\n",
       "      <td>RIPE</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22773</td>\n",
       "      <td>Cox Communications Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>ARIN</td>\n",
       "      <td>Cable/DSL/ISP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     asn                   org_name country source      info_type\n",
       "0   4436          GTT Americas, LLC      US   ARIN            NSP\n",
       "1  20940  Akamai International B.V.      NL   RIPE        Content\n",
       "2  31800                     DALnet      US   ARIN     Non-Profit\n",
       "3   3303      Swisscom (Schweiz) AG      CH   RIPE  Cable/DSL/ISP\n",
       "4  22773    Cox Communications Inc.      US   ARIN  Cable/DSL/ISP"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peering_df_joined = pd.merge(net_df, joined_df, left_on='asn', right_on='aut', how='left')\n",
    "peering_df_joined = peering_df_joined[['asn', 'org_name', 'country', 'source', 'info_type']]\n",
    "peering_df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e33814ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cable/DSL/ISP           11787\n",
       "NSP                      3982\n",
       "Content                  2486\n",
       "Enterprise               1721\n",
       "Educational/Research     1457\n",
       "Network Services          804\n",
       "Route Server              623\n",
       "Non-Profit                613\n",
       "Government                126\n",
       "Route Collector            31\n",
       "Name: info_type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peering_df_joined['info_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408e215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "/home/vscode/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 739/739 [02:35<00:00,  4.75it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3470052083333333\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Cable/DSL/ISP       0.75      0.39      0.52      1532\n",
      "             Content       0.25      0.29      0.27       323\n",
      "Educational/Research       0.40      0.54      0.46       189\n",
      "          Enterprise       0.16      0.28      0.21       224\n",
      "          Government       0.17      0.25      0.21        16\n",
      "                 NSP       0.27      0.22      0.24       518\n",
      "    Network Services       0.04      0.12      0.06       105\n",
      "          Non-Profit       0.15      0.36      0.21        80\n",
      "     Route Collector       0.08      0.25      0.12         4\n",
      "        Route Server       0.19      0.54      0.28        81\n",
      "\n",
      "            accuracy                           0.35      3072\n",
      "           macro avg       0.25      0.33      0.26      3072\n",
      "        weighted avg       0.49      0.35      0.39      3072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 38.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         org_name       predicted_label\n",
      "0     new org llc      Network Services\n",
      "1  university xyz  Educational/Research\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'clickhouse-client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m net_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclickhouse-client\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--query\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mINSERT INTO predictions FORMAT CSV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictions.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'clickhouse-client'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Angenommen, dein DataFrame ist 'df' mit Spalten 'asn', 'org_name', 'country', 'source' und 'label' (die Klasse)\n",
    "# Beispiel-DataFrame (ersetze durch deinen)\n",
    "df = peering_df_joined\n",
    "df['org_name'].fillna('Unknown', inplace=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU-Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Warnung: Keine GPU verfÃ¼gbar, CPU wird verwendet.\")\n",
    "\n",
    "# BERT-Tokenizer und Model laden (pre-trained bert-base-uncased)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "model.eval()  # FÃ¼r Inference\n",
    "\n",
    "# Funktion fÃ¼r BERT-Embeddings (CLS-Token als Sentence-Embedding)\n",
    "def get_bert_embedding(text, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(text), batch_size)):\n",
    "        batch = text[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS-Token\n",
    "            embeddings.append(cls_embeddings.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Extrahiere Embeddings fÃ¼r org_name\n",
    "X_embeddings = get_bert_embedding(df['org_name'].tolist())\n",
    "\n",
    "# Labels\n",
    "y = df['info_type']\n",
    "\n",
    "# Train/Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.13, random_state=42, stratify=y)\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# Balancing\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_bal, y_train_bal = rus.fit_resample(X_train_res, y_train_res)\n",
    "\n",
    "# Classifier\n",
    "classifier = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "classifier.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Anwendung auf net_df\n",
    "output_df_bert = pd.DataFrame({'org_name': ['New Org LLC', 'University XYZ']})\n",
    "output_df_bert['org_name'] = output_df_bert['org_name'].str.lower()\n",
    "new_embeddings = get_bert_embedding(output_df_bert['org_name'].tolist())\n",
    "output_df_bert['predicted_label'] = classifier.predict(new_embeddings)\n",
    "print(output_df_bert)\n",
    "\n",
    "# Optional: ClickHouse Export\n",
    "output_df_bert.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           aut     changed            org_id source  \\\n",
      "0            1  20240618.0      LPL-141-ARIN   ARIN   \n",
      "1            2  20231108.0  UNIVER-19-Z-ARIN   ARIN   \n",
      "2            3  20100927.0        MIT-2-ARIN   ARIN   \n",
      "3            4  20230929.0     USC-32-Z-ARIN   ARIN   \n",
      "4            5  20200723.0      WGL-117-ARIN   ARIN   \n",
      "...        ...         ...               ...    ...   \n",
      "119408  402035  20250930.0      SL-2249-ARIN   ARIN   \n",
      "119409  402036  20251001.0      GOAUT-1-ARIN   ARIN   \n",
      "119410  402037  20251001.0       @del-402037   ARIN   \n",
      "119411  402331  20250418.0      UHS-206-ARIN   ARIN   \n",
      "119412  402332  20241030.0       IH-165-ARIN   ARIN   \n",
      "\n",
      "                                     org_name country  \n",
      "0                         Level 3 Parent, LLC      US  \n",
      "1                      University of Delaware      US  \n",
      "2       Massachusetts Institute of Technology      US  \n",
      "3           University of Southern California      US  \n",
      "4                               WFA Group LLC      US  \n",
      "...                                       ...     ...  \n",
      "119408             Sergeant Laboratories, Inc      US  \n",
      "119409                         GoAutomate Inc      CA  \n",
      "119410                                unknown      US  \n",
      "119411              UNIVERSAL HEALTH SERVICES      US  \n",
      "119412                     IQVIA Holdings Inc      US  \n",
      "\n",
      "[119413 rows x 6 columns]\n",
      "           aut                               org_name\n",
      "0            1                    Level 3 Parent, LLC\n",
      "1            2                 University of Delaware\n",
      "2            3  Massachusetts Institute of Technology\n",
      "3            4      University of Southern California\n",
      "4            5                          WFA Group LLC\n",
      "...        ...                                    ...\n",
      "119408  402035             Sergeant Laboratories, Inc\n",
      "119409  402036                         GoAutomate Inc\n",
      "119410  402037                                unknown\n",
      "119411  402331              UNIVERSAL HEALTH SERVICES\n",
      "119412  402332                     IQVIA Holdings Inc\n",
      "\n",
      "[119413 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2528/3798791699.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bert_df.fillna('unknown', inplace=True)\n",
      "/tmp/ipykernel_2528/3798791699.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bert_df['label'] = classifier.predict(new_embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           aut                               org_name                 label\n",
      "0            1                    Level 3 Parent, LLC               Content\n",
      "1            2                 University of Delaware  Educational/Research\n",
      "2            3  Massachusetts Institute of Technology  Educational/Research\n",
      "3            4      University of Southern California  Educational/Research\n",
      "4            5                          WFA Group LLC            Enterprise\n",
      "...        ...                                    ...                   ...\n",
      "119408  402035             Sergeant Laboratories, Inc               Content\n",
      "119409  402036                         GoAutomate Inc            Enterprise\n",
      "119410  402037                                unknown  Educational/Research\n",
      "119411  402331              UNIVERSAL HEALTH SERVICES          Route Server\n",
      "119412  402332                     IQVIA Holdings Inc            Non-Profit\n",
      "\n",
      "[119413 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aut</th>\n",
       "      <th>org_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Level 3 Parent, LLC</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>University of Delaware</td>\n",
       "      <td>Educational/Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Educational/Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>University of Southern California</td>\n",
       "      <td>Educational/Research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>WFA Group LLC</td>\n",
       "      <td>Enterprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aut                               org_name                 label\n",
       "0    1                    Level 3 Parent, LLC               Content\n",
       "1    2                 University of Delaware  Educational/Research\n",
       "2    3  Massachusetts Institute of Technology  Educational/Research\n",
       "3    4      University of Southern California  Educational/Research\n",
       "4    5                          WFA Group LLC            Enterprise"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(joined_df)\n",
    "bert_df = joined_df[['aut', 'org_name']]\n",
    "print(bert_df)\n",
    "bert_df.fillna('unknown', inplace=True)\n",
    "new_embeddings = get_bert_embedding(bert_df.tolist())\n",
    "bert_df['label'] = classifier.predict(new_embeddings)\n",
    "print(bert_df)\n",
    "bert_df.to_csv('all_asn.csv', index=False)\n",
    "bert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "392aae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU-Name: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "          asn                                           org_name country  \\\n",
      "0        4436                                  gtt americas, llc      US   \n",
      "1       20940                          akamai international b.v.      NL   \n",
      "2       31800                                             dalnet      US   \n",
      "3        3303                              swisscom (schweiz) ag      CH   \n",
      "4       22773                            cox communications inc.      US   \n",
      "...       ...                                                ...     ...   \n",
      "23625  154232  max technology & support services private limited      IN   \n",
      "23626  204856                                            unknown     NaN   \n",
      "23627  204917                                            unknown     NaN   \n",
      "23628  210796                                    bjoern schleyer      DE   \n",
      "23629  400926                                       kiwi telecom      US   \n",
      "\n",
      "      source             info_type  \n",
      "0       ARIN                   NSP  \n",
      "1       RIPE               Content  \n",
      "2       ARIN            Non-Profit  \n",
      "3       RIPE         Cable/DSL/ISP  \n",
      "4       ARIN         Cable/DSL/ISP  \n",
      "...      ...                   ...  \n",
      "23625  APNIC         Cable/DSL/ISP  \n",
      "23626    NaN  Educational/Research  \n",
      "23627    NaN         Cable/DSL/ISP  \n",
      "23628   RIPE                   NSP  \n",
      "23629   ARIN                   NSP  \n",
      "\n",
      "[23630 rows x 5 columns]\n",
      "Verwendete Klassen: ['Cable/DSL/ISP', 'NSP', 'Content', 'Enterprise', 'Educational/Research', 'Network Services', 'Route Server', 'Non-Profit', 'Government', 'Route Collector']\n",
      "DataFrame nach Filterung: 23630 Zeilen\n",
      "Eindeutige org_name: 20832\n",
      "\n",
      "=== BERT-Modell ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "BERT-Embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 326/326 [00:09<00:00, 35.55it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Accuracy: 0.34403839055001845\n",
      "BERT Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Cable/DSL/ISP       0.77      0.41      0.53      1418\n",
      "             Content       0.21      0.29      0.24       277\n",
      "Educational/Research       0.38      0.47      0.42       170\n",
      "          Enterprise       0.15      0.23      0.18       201\n",
      "          Government       0.38      0.50      0.43        16\n",
      "                 NSP       0.24      0.23      0.23       436\n",
      "    Network Services       0.03      0.12      0.05        91\n",
      "          Non-Profit       0.11      0.31      0.16        61\n",
      "     Route Collector       0.00      0.00      0.00         2\n",
      "        Route Server       0.10      0.32      0.15        37\n",
      "\n",
      "            accuracy                           0.34      2709\n",
      "           macro avg       0.24      0.29      0.24      2709\n",
      "        weighted avg       0.51      0.34      0.39      2709\n",
      "\n",
      "\n",
      "=== TF-IDF-Modell ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Accuracy: 0.5197489848652639\n",
      "TF-IDF Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Cable/DSL/ISP       0.65      0.78      0.71      1418\n",
      "             Content       0.27      0.31      0.29       277\n",
      "Educational/Research       0.48      0.43      0.45       170\n",
      "          Enterprise       0.23      0.14      0.17       201\n",
      "          Government       0.33      0.19      0.24        16\n",
      "                 NSP       0.26      0.21      0.23       436\n",
      "    Network Services       0.06      0.01      0.02        91\n",
      "          Non-Profit       0.50      0.13      0.21        61\n",
      "     Route Collector       0.00      0.00      0.00         2\n",
      "        Route Server       0.57      0.32      0.41        37\n",
      "\n",
      "            accuracy                           0.52      2709\n",
      "           macro avg       0.34      0.25      0.27      2709\n",
      "        weighted avg       0.48      0.52      0.49      2709\n",
      "\n",
      "Test-Datensatz LÃ¤nge: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT-Embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 77.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Embedding LÃ¤nge: 7\n",
      "\n",
      "Ad-hoc-Test Ergebnisse:\n",
      "           org_name  predicted_label_bert predicted_label_tfidf\n",
      "0        google llc  Educational/Research               Content\n",
      "1    university xyz      Network Services  Educational/Research\n",
      "2  verizon business            Enterprise                   NSP\n",
      "3  cloudflare, inc.               Content               Content\n",
      "4               mit  Educational/Research         Cable/DSL/ISP\n",
      "5  amazon.com, inc.               Content            Enterprise\n",
      "6       unknown org            Non-Profit            Non-Profit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "# Initialize parallel_pandas\n",
    "\n",
    "# PrÃ¼fe GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU-Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Warnung: Keine GPU verfÃ¼gbar, CPU wird verwendet.\")\n",
    "\n",
    "# DataFrame (dein echter Datensatz, hier Beispiel\n",
    "df = peering_df_joined\n",
    "# Preprocessing\n",
    "df['org_name'] = df['org_name'].fillna('Unknown').str.lower()\n",
    "\n",
    "# Filtere Klassen mit <2 EintrÃ¤gen\n",
    "class_counts = df['info_type'].value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "df = df[df['info_type'].isin(valid_classes)]\n",
    "print(df)\n",
    "print(f\"Verwendete Klassen: {valid_classes.tolist()}\")\n",
    "print(f\"DataFrame nach Filterung: {len(df)} Zeilen\")\n",
    "\n",
    "# Deduplizierung\n",
    "unique_df = df.drop_duplicates(subset=['org_name'])\n",
    "print(f\"Eindeutige org_name: {len(unique_df)}\")\n",
    "\n",
    "\n",
    "# --- BERT-Modell ---\n",
    "print(\"\\n=== BERT-Modell ===\")\n",
    "# BERT-Tokenizer und Model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "model.eval()\n",
    "\n",
    "# BERT Embeddings\n",
    "def get_bert_embedding(text, batch_size=64):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(text), batch_size), desc=\"BERT-Embeddings\"):\n",
    "        batch = text[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            embeddings.append(cls_embeddings.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Training\n",
    "X_bert = get_bert_embedding(unique_df['org_name'].tolist())\n",
    "y = unique_df['info_type']\n",
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(X_bert, y, test_size=0.13, random_state=42, stratify=y)\n",
    "\n",
    "# Balancing\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_bert, y_train)\n",
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_bal, y_train_bal = rus.fit_resample(X_train_res, y_train_res)\n",
    "\n",
    "# Classifier\n",
    "classifier_bert = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs', class_weight='balanced')\n",
    "classifier_bert.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_bert = classifier_bert.predict(X_test_bert)\n",
    "print(\"BERT Accuracy:\", accuracy_score(y_test, y_pred_bert))\n",
    "print(\"BERT Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_bert))\n",
    "\n",
    "# --- TF-IDF-Modell ---\n",
    "print(\"\\n=== TF-IDF-Modell ===\")\n",
    "# TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), lowercase=True)\n",
    "X_tfidf = vectorizer.fit_transform(unique_df['org_name'])\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.13, random_state=42, stratify=y)\n",
    "\n",
    "# Balancing\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train)\n",
    "X_train_bal, y_train_bal = rus.fit_resample(X_train_res, y_train_res)\n",
    "\n",
    "# Classifier\n",
    "classifier_tfidf = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs', class_weight='balanced')\n",
    "classifier_tfidf.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_tfidf = classifier_tfidf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"TF-IDF Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "\n",
    "# Ad-hoc-Test\n",
    "test_names = ['Google LLC', 'University XYZ', 'Verizon Business', 'Cloudflare, Inc.', 'MIT', 'Amazon.com, Inc.', 'Unknown Org']\n",
    "test_df = pd.DataFrame({'org_name': test_names})\n",
    "test_df['org_name'] = test_df['org_name'].str.lower()\n",
    "print(f\"Test-Datensatz LÃ¤nge: {len(test_df)}\")\n",
    "\n",
    "# BERT Vorhersagen\n",
    "test_embeddings = get_bert_embedding(test_df['org_name'].tolist())\n",
    "print(f\"BERT Embedding LÃ¤nge: {test_embeddings.shape[0]}\")\n",
    "test_df['predicted_label_bert'] = classifier_bert.predict(test_embeddings)\n",
    "\n",
    "# TF-IDF Vorhersagen\n",
    "test_tfidf = vectorizer.transform(test_df['org_name'])\n",
    "test_df['predicted_label_tfidf'] = classifier_tfidf.predict(test_tfidf)\n",
    "\n",
    "print(\"\\nAd-hoc-Test Ergebnisse:\")\n",
    "print(test_df[['org_name', 'predicted_label_bert', 'predicted_label_tfidf']])\n",
    "\n",
    "# ClickHouse Export\n",
    "test_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe891bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verwendete Klassen: ['Cable/DSL/ISP', 'NSP', 'Content', 'Enterprise', 'Educational/Research', 'Network Services', 'Route Server', 'Non-Profit', 'Government', 'Route Collector']\n",
      "DataFrame nach Filterung: 23630 Zeilen\n",
      "Eindeutige org_name: 20832\n",
      "\n",
      "=== BERT-Modell ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "BERT-Embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 326/326 [02:52<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Accuracy: 0.3359173126614987\n",
      "BERT Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Cable/DSL/ISP       0.76      0.40      0.53      1418\n",
      "             Content       0.21      0.27      0.23       277\n",
      "Educational/Research       0.33      0.43      0.37       170\n",
      "          Enterprise       0.15      0.23      0.18       201\n",
      "          Government       0.36      0.56      0.44        16\n",
      "                 NSP       0.24      0.22      0.23       436\n",
      "    Network Services       0.04      0.13      0.06        91\n",
      "          Non-Profit       0.08      0.25      0.13        61\n",
      "     Route Collector       0.00      0.00      0.00         2\n",
      "        Route Server       0.08      0.27      0.12        37\n",
      "\n",
      "            accuracy                           0.34      2709\n",
      "           macro avg       0.22      0.28      0.23      2709\n",
      "        weighted avg       0.50      0.34      0.38      2709\n",
      "\n",
      "\n",
      "=== TF-IDF-Modell ===\n",
      "TF-IDF Accuracy: 0.39313399778516056\n",
      "TF-IDF Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "       Cable/DSL/ISP       0.76      0.51      0.61      1418\n",
      "             Content       0.25      0.34      0.29       277\n",
      "Educational/Research       0.43      0.31      0.36       170\n",
      "          Enterprise       0.22      0.25      0.24       201\n",
      "          Government       0.19      0.44      0.26        16\n",
      "                 NSP       0.25      0.19      0.22       436\n",
      "    Network Services       0.05      0.13      0.07        91\n",
      "          Non-Profit       0.09      0.48      0.15        61\n",
      "     Route Collector       0.00      0.00      0.00         2\n",
      "        Route Server       0.23      0.43      0.30        37\n",
      "\n",
      "            accuracy                           0.39      2709\n",
      "           macro avg       0.25      0.31      0.25      2709\n",
      "        weighted avg       0.51      0.39      0.43      2709\n",
      "\n",
      "\n",
      "=== BM25-Modell ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 121\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Classifier\u001b[39;00m\n\u001b[1;32m    120\u001b[0m classifier_bm25 \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[43mclassifier_bm25\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_bal_bm25\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_bal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m    124\u001b[0m y_pred_bm25 \u001b[38;5;241m=\u001b[39m classifier_bm25\u001b[38;5;241m.\u001b[39mpredict(X_test_bm25)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:450\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    446\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[1;32m    447\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    448\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    449\u001b[0m ]\n\u001b[0;32m--> 450\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    459\u001b[0m     solver,\n\u001b[1;32m    460\u001b[0m     opt_res,\n\u001b[1;32m    461\u001b[0m     max_iter,\n\u001b[1;32m    462\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    463\u001b[0m )\n\u001b[1;32m    464\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_lbfgsb_py.py:361\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    355\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_linear_loss.py:274\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    271\u001b[0m n_dof \u001b[38;5;241m=\u001b[39m n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_prediction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     weights, intercept, raw_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_intercept_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from rank_bm25 import BM25Okapi\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# DataFrame (dein echter Datensatz)\n",
    "df = peering_df_joined\n",
    "\n",
    "# Preprocessing\n",
    "df['org_name'] = df['org_name'].fillna('unknown').str.lower()\n",
    "\n",
    "\n",
    "# Filtere Klassen mit <2 EintrÃ¤gen\n",
    "class_counts = df['info_type'].value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "df = df[df['info_type'].isin(valid_classes)]\n",
    "print(f\"Verwendete Klassen: {valid_classes.tolist()}\")\n",
    "print(f\"DataFrame nach Filterung: {len(df)} Zeilen\")\n",
    "\n",
    "# Deduplizierung\n",
    "unique_df = df.drop_duplicates(subset=['org_name'])\n",
    "print(f\"Eindeutige org_name: {len(unique_df)}\")\n",
    "\n",
    "# PrÃ¼fe Klassenanzahl\n",
    "if len(unique_df['info_type'].unique()) < 2:\n",
    "    print(\"Fehler: Nur eine Klasse nach Aggregation. Verwende stratify=None.\")\n",
    "    stratify = None\n",
    "else:\n",
    "    stratify = unique_df['info_type']\n",
    "\n",
    "# --- BERT-Modell ---\n",
    "print(\"\\n=== BERT-Modell ===\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "def get_bert_embedding(text, batch_size=64):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(text), batch_size), desc=\"BERT-Embeddings\"):\n",
    "        batch = text[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        inputs = {k: v for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            embeddings.append(cls_embeddings.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "X_bert = get_bert_embedding(unique_df['org_name'].tolist())\n",
    "y = unique_df['info_type']\n",
    "X_train_bert, X_test_bert, y_train, y_test = train_test_split(X_bert, y, test_size=0.13, random_state=42, stratify=stratify)\n",
    "\n",
    "# Skalierung\n",
    "scaler = StandardScaler()\n",
    "X_train_bal_bert = scaler.fit_transform(X_train_bert)\n",
    "X_test_bert = scaler.transform(X_test_bert)\n",
    "\n",
    "# Balancing\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_bal_bert, y_train)\n",
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_bal_bert, y_train_bal = rus.fit_resample(X_train_res, y_train_res)\n",
    "\n",
    "# Classifier\n",
    "classifier_bert = LogisticRegression(max_iter=5000, multi_class='multinomial', solver='lbfgs', class_weight='balanced')\n",
    "classifier_bert.fit(X_train_bal_bert, y_train_bal)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_bert = classifier_bert.predict(X_test_bert)\n",
    "print(\"BERT Accuracy:\", accuracy_score(y_test, y_pred_bert))\n",
    "print(\"BERT Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_bert, zero_division=0))\n",
    "\n",
    "# --- TF-IDF-Modell ---\n",
    "print(\"\\n=== TF-IDF-Modell ===\")\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), lowercase=True, max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(unique_df['org_name'])\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.13, random_state=42, stratify=stratify)\n",
    "\n",
    "# Balancing\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train)\n",
    "X_train_bal_tfidf, y_train_bal = rus.fit_resample(X_train_res, y_train_res)\n",
    "\n",
    "# Classifier\n",
    "classifier_tfidf = LogisticRegression(max_iter=5000, multi_class='multinomial', solver='lbfgs', class_weight='balanced')\n",
    "classifier_tfidf.fit(X_train_bal_tfidf, y_train_bal)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_tfidf = classifier_tfidf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"TF-IDF Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_tfidf, zero_division=0))\n",
    "\n",
    "# --- BM25-Modell ---\n",
    "print(\"\\n=== BM25-Modell ===\")\n",
    "# Tokenisierung fÃ¼r BM25\n",
    "tokenized_corpus = [doc.split() for doc in unique_df['org_name']]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# BM25-Features berechnen\n",
    "X_bm25 = np.array([bm25.get_scores(doc.split()) for doc in unique_df['org_name']])\n",
    "X_train_bm25, X_test_bm25, y_train, y_test = train_test_split(X_bm25, y, test_size=0.13, random_state=42, stratify=stratify)\n",
    "\n",
    "# Balancing\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_bm25, y_train)\n",
    "X_train_bal_bm25, y_train_bal = rus.fit_resample(X_train_res, y_train_res)\n",
    "\n",
    "# Classifier\n",
    "classifier_bm25 = LogisticRegression(max_iter=5000, multi_class='multinomial', solver='lbfgs', class_weight='balanced')\n",
    "classifier_bm25.fit(X_train_bal_bm25, y_train_bal)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_bm25 = classifier_bm25.predict(X_test_bm25)\n",
    "print(\"BM25 Accuracy:\", accuracy_score(y_test, y_pred_bm25))\n",
    "print(\"BM25 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_bm25, zero_division=0))\n",
    "\n",
    "# Ad-hoc-Test\n",
    "test_names = ['Google LLC', 'University XYZ', 'Verizon Business', 'Cloudflare, Inc.', 'MIT', 'Amazon.com, Inc.', 'Unknown Org']\n",
    "test_df = pd.DataFrame({'org_name': test_names})\n",
    "test_df['org_name'] = test_df['org_name'].str.lower()\n",
    "\n",
    "# BERT Vorhersagen\n",
    "test_embeddings = get_bert_embedding(test_df['org_name'].tolist())\n",
    "test_df['predicted_label_bert'] = classifier_bert.predict(scaler.transform(test_embeddings))\n",
    "\n",
    "# TF-IDF Vorhersagen\n",
    "test_tfidf = vectorizer.transform(test_df['org_name'])\n",
    "test_df['predicted_label_tfidf'] = classifier_tfidf.predict(test_tfidf)\n",
    "\n",
    "# BM25 Vorhersagen\n",
    "test_bm25 = np.array([bm25.get_scores(doc.split()) for doc in test_df['org_name']])\n",
    "test_df['predicted_label_bm25'] = classifier_bm25.predict(test_bm25)\n",
    "\n",
    "# Kombiniere regelbasierte und modellbasierte Vorhersagen\n",
    "test_df['final_label'] = test_df.apply(lambda x: x['rule_label'] if x['rule_label'] else x['predicted_label_tfidf'], axis=1)\n",
    "\n",
    "print(\"\\nAd-hoc-Test Ergebnisse:\")\n",
    "print(test_df[['org_name', 'rule_label', 'predicted_label_bert', 'predicted_label_tfidf', 'predicted_label_bm25', 'final_label']])\n",
    "\n",
    "# ClickHouse Export\n",
    "test_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
